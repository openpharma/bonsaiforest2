[{"path":"https://openpharma.github.io/bonsaiforest2/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 bonsaiforest2 authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"handling-exposure-in-count-outcomes-with-offsets","dir":"Articles","previous_headings":"","what":"Handling Exposure in Count Outcomes with Offsets","title":"Advanced Functionalities","text":"count data (like disease exacerbations event rates), observed count often depends exposure time follow-time. Using offset variable standard statistical method properly account time variation modeling event rate (count per unit time) instead raw count. bonsaiforest2, can include offset directly response_formula_str using standard brms syntax: outcome + offset(log_time) ~ predictors.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"example-1-count-outcome-with-offset-disease-exacerbations","dir":"Articles","previous_headings":"1 Handling Exposure in Count Outcomes with Offsets","what":"Example 1: Count Outcome with Offset (Disease Exacerbations)","title":"Advanced Functionalities","text":"scenario models exacerbation counts using Negative Binomial distribution explicitly accounts patient’s exposure time. Scenario: Modeling exacerbation counts. Adjust baseline_severity (unshrunk) many exploratory biomarkers (shrunk). interaction terms (overall treatment effect ).","code":"# Data Simulation  set.seed(789) library(bonsaiforest2) n_patients <- 150 biomarker_data <- as.data.frame(matrix(rnorm(n_patients * 10), ncol = 10)) names(biomarker_data) <- paste0(\"biomarker_\", 1:10) count_data <- data.frame(   exacerbation_count = rnbinom(n_patients, size = 1.5, mu = 3),   medication = sample(0:1, n_patients, replace = TRUE),   baseline_severity = rnorm(n_patients, 10, 2),   log_exposure_time = log(runif(n_patients, 0.5, 1.5)) # Example offset ) count_data <- cbind(count_data, biomarker_data) count_data$medication <- factor(count_data$medication, levels = c(0, 1))  # Create formula string for all biomarkers (Prognostic effects only here) shrunk_prog_str <- paste(\"~\", paste(names(biomarker_data), collapse = \" + \")) # Model Fitting with Offset count_model_fit <- run_brms_analysis(   data = count_data,   # Include offset(log_exposure_time) directly in the response formula   response_formula_str = \"exacerbation_count + offset(log_exposure_time) ~ medication\",   response_type = \"count\",   unshrunk_prognostic_formula_str = \"~ 1 + baseline_severity\",   shrunk_prognostic_formula_str = shrunk_prog_str,   chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = \"cmdstanr\" ) #> Step 1: Preparing formula and data... #> Treatment 'medication' added to unshrunk prognostic terms by default. #>  #> Step 2: Fitting the brms model... #> Using default priors for unspecified effects: #>   - shrunk prognostic (b): horseshoe(1) #>   - unshrunk prognostic (b): normal(0, 5) #>   - prognostic intercept: normal(0, 5) #> Fitting brms model... #> Start sampling #> Running MCMC with 1 chain... #>  #> Chain 1 WARNING: There aren't enough warmup iterations to fit the  #> Chain 1          three stages of adaptation as currently configured.  #> Chain 1          Reducing each adaptation stage to 15%/75%/10% of  #> Chain 1          the given number of warmup iterations:  #> Chain 1            init_buffer = 15  #> Chain 1            adapt_window = 75  #> Chain 1            term_buffer = 10  #> Chain 1 finished in 2.7 seconds. #> Loading required namespace: rstan #>  #> Analysis complete."},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"customizing-prior-distributions","dir":"Articles","previous_headings":"","what":"Customizing Prior Distributions","title":"Advanced Functionalities","text":"choice prior central Bayesian shrinkage. bonsaiforest2 provides sensible defaults, allows full customization using prognostic_effect_priors predictive_effect_priors arguments.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"prior-specification-mechanics","dir":"Articles","previous_headings":"2 Customizing Prior Distributions","what":"Prior Specification Mechanics","title":"Advanced Functionalities","text":"specify priors named lists containing strings, passed brms::set_prior().","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"prior-recommendations-for-non-shrunk-terms","dir":"Articles","previous_headings":"2 Customizing Prior Distributions > 2.1 Prior Specification Mechanics","what":"Prior Recommendations for Non-Shrunk Terms","title":"Advanced Functionalities","text":"non-shrunk (fixed) effects, choosing weakly informative prior critical stabilize model without unduly influencing results. robust strategy scale priors based standard deviation (SD) outcome variable. \\[\\sigma_{outcome} = \\text{SD}(\\text{Outcome})\\]","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"practical-examples-of-prior-setting","dir":"Articles","previous_headings":"2 Customizing Prior Distributions","what":"Practical Examples of Prior Setting","title":"Advanced Functionalities","text":"provide functional example, generate synthetic dataset mirrors structure Tirzepatide (SURPASS-2) trial case study described Wang et al. (2024). study used continuous endpoint (change HbA1c), fits perfectly code snippet calculating standard deviation (sd).","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"dataset-generation-and-model-preparation-synthetic-surpass-2","dir":"Articles","previous_headings":"2 Customizing Prior Distributions > 2.2 Practical Examples of Prior Setting","what":"Dataset Generation and Model Preparation (Synthetic SURPASS-2)","title":"Advanced Functionalities","text":"dataset mimics clinical trial comparing Treatment (Tirzepatide) vs. Control (Semaglutide), looking subgroups defined Sex, Race, Age Group.","code":"# Prerequisites: Ensure packages used by your function are loaded library(survival) # For Surv() library(brms)     # For brmsformula objects #> Loading required package: Rcpp #> Loading 'brms' package (version 2.23.0). Useful instructions #> can be found by typing help('brms'). A more detailed introduction #> to the package is available through vignette('brms_overview'). #>  #> Attaching package: 'brms' #> The following object is masked from 'package:survival': #>  #>     kidney #> The following object is masked from 'package:stats': #>  #>     ar library(bonsaiforest2)  # 1. Create Sample Data (matching your @examples section) set.seed(123) n <- 100 sim_data <- data.frame(   time = round(runif(n, 1, 100)),   status = sample(0:1, n, replace = TRUE),   trt = sample(0:1, n, replace = TRUE),   age = rnorm(n, 50, 10),   region = sample(c(\"A\", \"B\"), n, replace = TRUE),   subgroup = sample(c(\"S1\", \"S2\", \"S3\"), n, replace = TRUE) )  # Ensure variables are factors where appropriate sim_data$trt <- factor(sim_data$trt, levels = c(0, 1)) sim_data$region <- as.factor(sim_data$region) sim_data$subgroup <- as.factor(sim_data$subgroup)  # 2. Run prepare_formula_model # This transforms the data (creating dummy variables for interactions) # and builds the non-linear brms formula. prepared_model <- prepare_formula_model(   data = sim_data,      # Main response variable and treatment identifier   response_formula_str = \"Surv(time, status) ~ trt\",      # Predictive (Interaction) effects to be shrunk   # Note: The function will automatically generate dummy columns for 'subgroup'   shrunk_predictive_formula_str = \"~ trt:subgroup\",      # Prognostic (Main) effects: Unshrunk (Fixed)   unshrunk_prognostic_formula_str = \"~ age\",      # Prognostic (Main) effects: Shrunk (Regularized)   shrunk_prognostic_formula_str = \"~ region\",      # Model type   response_type = \"survival\",      # Stratify the baseline hazard by region   stratification_formula_str = \"~ region\" ) #> Response type is 'survival'. Modeling the baseline hazard explicitly using bhaz(). #> Applying stratification: estimating separate baseline hazards by 'region'. #> Treatment 'trt' added to unshrunk prognostic terms by default. #> Auto-adding missing prognostic effect for interaction: subgroup  # 3. Inspect the Results  # A. The generated brms formula object # You should see parts for 'unprogeffect', 'shprogeffect', etc. print(prepared_model$formula) #> time | cens(1 - status) + bhaz(Boundary.knots = c(0.02, 99.98), knots = c(24, 46, 69), intercept = FALSE, gr = region) ~ unprogeffect + shprogeffect + shpredeffect  #> unprogeffect ~ age + trt + subgroup + 0 #> shprogeffect ~ region + 0 #> shpredeffect ~ subgroup_S1_x_trt + subgroup_S2_x_trt + subgroup_S3_x_trt + 0  # B. The processed data # You should see new columns like 'subgroup_S1_x_trt', 'subgroup_S2_x_trt', etc. head(prepared_model$data) #>   time status trt      age region subgroup subgroup_S1_x_trt subgroup_S2_x_trt #> 1   29      0   1 57.87739      B       S2                 0                 1 #> 2   79      1   1 57.69042      B       S1                 1                 0 #> 3   41      1   1 53.32203      B       S3                 0                 0 #> 4   88      0   0 39.91623      B       S3                 0                 0 #> 5   94      1   1 48.80547      A       S3                 0                 0 #> 6    6      1   1 47.19605      A       S2                 0                 1 #>   subgroup_S3_x_trt #> 1                 0 #> 2                 0 #> 3                 1 #> 4                 0 #> 5                 1 #> 6                 0"},{"path":[]},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"example-2-using-recommended-weakly-informative-priors","dir":"Articles","previous_headings":"2 Customizing Prior Distributions > 2.2 Practical Examples of Prior Setting","what":"Example 2: Using Recommended Weakly Informative Priors","title":"Advanced Functionalities","text":"easiest example can . Just use recommended priors without tunning.","code":"fit_ex3 <- fit_brms_model(   prepared_model = prepared_model ) #> Using default priors for unspecified effects: #>   - shrunk prognostic (b): horseshoe(1) #>   - unshrunk prognostic (b): normal(0, 5) #>   - shrunk predictive (b): horseshoe(1) #> Fitting brms model... #> Compiling Stan program... #> Trying to compile a simple C file #> Running /opt/R/4.5.2/lib/R/bin/R CMD SHLIB foo.c #> using C compiler: ‘gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0’ #> gcc -std=gnu2x -I\"/opt/R/4.5.2/lib/R/include\" -DNDEBUG   -I\"/home/runner/work/_temp/Library/Rcpp/include/\"  -I\"/home/runner/work/_temp/Library/RcppEigen/include/\"  -I\"/home/runner/work/_temp/Library/RcppEigen/include/unsupported\"  -I\"/home/runner/work/_temp/Library/BH/include\" -I\"/home/runner/work/_temp/Library/StanHeaders/include/src/\"  -I\"/home/runner/work/_temp/Library/StanHeaders/include/\"  -I\"/home/runner/work/_temp/Library/RcppParallel/include/\"  -I\"/home/runner/work/_temp/Library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/home/runner/work/_temp/Library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include    -fpic  -g -O2  -c foo.c -o foo.o #> In file included from /home/runner/work/_temp/Library/RcppEigen/include/Eigen/Core:19, #>                  from /home/runner/work/_temp/Library/RcppEigen/include/Eigen/Dense:1, #>                  from /home/runner/work/_temp/Library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22, #>                  from <command-line>: #> /home/runner/work/_temp/Library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory #>   679 | #include <cmath> #>       |          ^~~~~~~ #> compilation terminated. #> make: *** [/opt/R/4.5.2/lib/R/etc/Makeconf:202: foo.o] Error 1 #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000127 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.27 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 5.119 seconds (Warm-up) #> Chain 1:                1.854 seconds (Sampling) #> Chain 1:                6.973 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 6.5e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.65 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 5.459 seconds (Warm-up) #> Chain 2:                1.655 seconds (Sampling) #> Chain 2:                7.114 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 6e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.6 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 4.959 seconds (Warm-up) #> Chain 3:                1.732 seconds (Sampling) #> Chain 3:                6.691 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 6e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.6 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 5.2 seconds (Warm-up) #> Chain 4:                2.044 seconds (Sampling) #> Chain 4:                7.244 seconds (Total) #> Chain 4: #> Warning: There were 4 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems"},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"example-3-using-the-r2d2-shrinkage-prior","dir":"Articles","previous_headings":"2 Customizing Prior Distributions > 2.2 Practical Examples of Prior Setting","what":"Example 3: Using the R2D2 Shrinkage Prior","title":"Advanced Functionalities","text":"R2D2 prior useful want control global shrinkage via coefficient determination (\\(R^2\\)) rather scale parameter \\(\\tau\\). often interpretable stakeholders.","code":"# Use a custom R2D2 string for the shrunk predictive effects (interactions) # mean_R2 = 0.5 implies we expect the subgroups to explain 50% of the variance r2d2_prior_string <- \"R2D2(mean_R2 = 0.5, prec_R2 = 1)\"   fit_ex4 <- fit_brms_model(   prepared_model = prepared_model,   predictive_effect_priors = list(shrunk = r2d2_prior_string) ) #> Using default priors for unspecified effects: #>   - shrunk prognostic (b): horseshoe(1) #>   - unshrunk prognostic (b): normal(0, 5) #> Fitting brms model... #> Compiling Stan program... #> Trying to compile a simple C file #> Running /opt/R/4.5.2/lib/R/bin/R CMD SHLIB foo.c #> using C compiler: ‘gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0’ #> gcc -std=gnu2x -I\"/opt/R/4.5.2/lib/R/include\" -DNDEBUG   -I\"/home/runner/work/_temp/Library/Rcpp/include/\"  -I\"/home/runner/work/_temp/Library/RcppEigen/include/\"  -I\"/home/runner/work/_temp/Library/RcppEigen/include/unsupported\"  -I\"/home/runner/work/_temp/Library/BH/include\" -I\"/home/runner/work/_temp/Library/StanHeaders/include/src/\"  -I\"/home/runner/work/_temp/Library/StanHeaders/include/\"  -I\"/home/runner/work/_temp/Library/RcppParallel/include/\"  -I\"/home/runner/work/_temp/Library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/home/runner/work/_temp/Library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include    -fpic  -g -O2  -c foo.c -o foo.o #> In file included from /home/runner/work/_temp/Library/RcppEigen/include/Eigen/Core:19, #>                  from /home/runner/work/_temp/Library/RcppEigen/include/Eigen/Dense:1, #>                  from /home/runner/work/_temp/Library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22, #>                  from <command-line>: #> /home/runner/work/_temp/Library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory #>   679 | #include <cmath> #>       |          ^~~~~~~ #> compilation terminated. #> make: *** [/opt/R/4.5.2/lib/R/etc/Makeconf:202: foo.o] Error 1 #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000104 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.04 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 5.074 seconds (Warm-up) #> Chain 1:                2.443 seconds (Sampling) #> Chain 1:                7.517 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 5.7e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.57 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 5.32 seconds (Warm-up) #> Chain 2:                2.182 seconds (Sampling) #> Chain 2:                7.502 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 5.8e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.58 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 4.686 seconds (Warm-up) #> Chain 3:                1.578 seconds (Sampling) #> Chain 3:                6.264 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 5.3e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.53 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 5.066 seconds (Warm-up) #> Chain 4:                1.633 seconds (Sampling) #> Chain 4:                6.699 seconds (Total) #> Chain 4: #> Warning: There were 6 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems"},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"example-4-custom-hierarchical-prior-advanced","dir":"Articles","previous_headings":"2 Customizing Prior Distributions > 2.2 Practical Examples of Prior Setting","what":"Example 4: Custom Hierarchical Prior (Advanced)","title":"Advanced Functionalities","text":"example demonstrates injecting raw Stan code. necessary want implement hierarchical structure brms support natively, linking specific coefficients via custom global parameter \\(\\tau_{pred}\\). #Stratification Nuisance Parameters many trials, parameters like observation error variance (\\(\\sigma^2\\) continuous outcomes) baseline hazard function (\\(h_0(t)\\) survival outcomes) known vary site, country, factors. Stratification models known heterogeneity fitting nuisance parameters separately level grouping variable. Use stratification_formula_str argument define grouping factor(s).","code":"library(brms)  # 1. Define a new hyperparameter 'tau_pred' for the Stan code stanvars_full_hierarchical <- brms::stanvar(   scode = \"  real mu_pred;\\n  real<lower=0> sigma_pred;\\n\",   block = \"parameters\" ) +   brms::stanvar(     scode = \"  // Priors on the hierarchical parameters\\n  target += normal_lpdf(mu_pred | 0, 4); \\n  target += normal_lpdf(sigma_pred | 0, 1) - normal_lccdf(0 | 0, 1); \\n\",     block = \"model\"   )  #  prior_full_hierarchical <- brms::set_prior(\"normal(mu_pred, sigma_pred)\")  # 3. Pass both objects to the function fit_ex5 <- fit_brms_model(   prepared_model = prepared_model,   predictive_effect_priors = list(shrunk = prior_full_hierarchical),   stanvars = stanvars_full_hierarchical ) #> Re-targeting 'brmsprior' object for nlpar: shpredeffect class: b #> Using default priors for unspecified effects: #>   - shrunk prognostic (b): horseshoe(1) #>   - unshrunk prognostic (b): normal(0, 5) #> Fitting brms model... #> Compiling Stan program... #> Trying to compile a simple C file #> Running /opt/R/4.5.2/lib/R/bin/R CMD SHLIB foo.c #> using C compiler: ‘gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0’ #> gcc -std=gnu2x -I\"/opt/R/4.5.2/lib/R/include\" -DNDEBUG   -I\"/home/runner/work/_temp/Library/Rcpp/include/\"  -I\"/home/runner/work/_temp/Library/RcppEigen/include/\"  -I\"/home/runner/work/_temp/Library/RcppEigen/include/unsupported\"  -I\"/home/runner/work/_temp/Library/BH/include\" -I\"/home/runner/work/_temp/Library/StanHeaders/include/src/\"  -I\"/home/runner/work/_temp/Library/StanHeaders/include/\"  -I\"/home/runner/work/_temp/Library/RcppParallel/include/\"  -I\"/home/runner/work/_temp/Library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/home/runner/work/_temp/Library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include    -fpic  -g -O2  -c foo.c -o foo.o #> In file included from /home/runner/work/_temp/Library/RcppEigen/include/Eigen/Core:19, #>                  from /home/runner/work/_temp/Library/RcppEigen/include/Eigen/Dense:1, #>                  from /home/runner/work/_temp/Library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22, #>                  from <command-line>: #> /home/runner/work/_temp/Library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory #>   679 | #include <cmath> #>       |          ^~~~~~~ #> compilation terminated. #> make: *** [/opt/R/4.5.2/lib/R/etc/Makeconf:202: foo.o] Error 1 #> Start sampling #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 9.2e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.92 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 8.37 seconds (Warm-up) #> Chain 1:                8.686 seconds (Sampling) #> Chain 1:                17.056 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 5e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.5 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 7.642 seconds (Warm-up) #> Chain 2:                0.12 seconds (Sampling) #> Chain 2:                7.762 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 5e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.5 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 7.693 seconds (Warm-up) #> Chain 3:                3.831 seconds (Sampling) #> Chain 3:                11.524 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 5.1e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.51 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 7.591 seconds (Warm-up) #> Chain 4:                4.545 seconds (Sampling) #> Chain 4:                12.136 seconds (Total) #> Chain 4: #> Warning: There were 1310 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is 1.56, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess"},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"example-5-stratified-continuous-model","dir":"Articles","previous_headings":"2 Customizing Prior Distributions","what":"Example 5: Stratified Continuous Model","title":"Advanced Functionalities","text":"Scenario: model SBP change observation variance \\(\\sigma^2\\) differs \\(\\text{clinic\\_site}\\). modeled stratifying \\(\\sigma\\) parameter Normal distribution site variable.","code":"set.seed(42) n_patients <- 180 sigma_by_site <- c(SiteA = 6, SiteB = 12, SiteC = 18) sample_data_strat_cont <- data.frame(     id = 1:n_patients,     clinic_site = factor(sample(c(\"SiteA\", \"SiteB\", \"SiteC\"), n_patients, replace = TRUE)) ) sample_data_strat_cont$trt <- factor(sample(0:1, n_patients, replace = TRUE, prob = c(0.5, 0.5))) sample_data_strat_cont$baseline_sbp <- rnorm(n_patients, mean = 145, sd = 8) sample_data_strat_cont$age_group <- factor(sample(c(\"Under60\", \"Over60\"), n_patients, replace = TRUE)) noise <- rnorm(n_patients, mean = 0, sd = sigma_by_site[sample_data_strat_cont$clinic_site]) sample_data_strat_cont$sbp_change <- -5 - (as.integer(sample_data_strat_cont$trt)-1) * 8 -                                      0.2 * (sample_data_strat_cont$baseline_sbp - 145) +                                      (as.integer(sample_data_strat_cont$trt)-1) * ifelse(sample_data_strat_cont$age_group == \"Over60\", -5, 0) +                                      noise # Model Fitting with Stratified Sigma fit_continuous_stratified <- run_brms_analysis(   data = sample_data_strat_cont,   response_formula_str = \"sbp_change ~ trt\",   response_type = \"continuous\",   unshrunk_prognostic_formula_str = \"~ baseline_sbp\",   shrunk_predictive_formula_str = \"~ age_group:trt\",   stratification_formula_str = \"~ clinic_site\",   chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = \"cmdstanr\" ) #> Step 1: Preparing formula and data... #> Applying stratification: estimating sigma by 'clinic_site'. #> Treatment 'trt' added to unshrunk prognostic terms by default. #> Auto-adding missing prognostic effect for interaction: age_group #>  #> Step 2: Fitting the brms model... #> Using default priors for unspecified effects: #>   - unshrunk prognostic (b): normal(0, 5) #>   - prognostic intercept: normal(0, 5) #>   - shrunk predictive (b): horseshoe(1) #> Fitting brms model... #> Start sampling #> Running MCMC with 1 chain... #>  #> Chain 1 WARNING: There aren't enough warmup iterations to fit the  #> Chain 1          three stages of adaptation as currently configured.  #> Chain 1          Reducing each adaptation stage to 15%/75%/10% of  #> Chain 1          the given number of warmup iterations:  #> Chain 1            init_buffer = 15  #> Chain 1            adapt_window = 75  #> Chain 1            term_buffer = 10  #> Chain 1 finished in 2.7 seconds. #> Warning: 82 of 100 (82.0%) transitions hit the maximum treedepth limit of 10. #> See https://mc-stan.org/misc/warnings for details. #>  #> Analysis complete. strat_continuous_summary <- summary_subgroup_effects(   brms_fit = fit_continuous_stratified,   original_data = sample_data_strat_cont,   trt_var = \"trt\",   response_type = \"continuous\" # Auto-detects age_group interaction ) #> --- Calculating specific subgroup effects... --- #> `subgroup_vars` set to 'auto'. Detecting from model interaction terms... #> ...detected subgroup variable(s): age_group #> Step 1: Creating counterfactual datasets... #> ...setting interaction dummy variables for the 'all treatment' scenario. #> Step 2: Generating posterior predictions... #> ... (predicting expected outcomes)... #> Step 3: Calculating marginal effects... #> ... processing age_group #> Done.  print(strat_continuous_summary$estimates) #> # A tibble: 2 × 4 #>   Subgroup           Median CI_Lower CI_Upper #>   <chr>               <dbl>    <dbl>    <dbl> #> 1 age_group: Over60  -10.8     -14.5    -7.17 #> 2 age_group: Under60  -7.95    -12.0    -5.00 plot(strat_continuous_summary, title = \"Stratified Continuous: Subgroup Effects\") #> Preparing data for plotting... #> Generating plot... #> Done."},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Advanced_Functionalities.html","id":"example-6-stratified-survival-model","dir":"Articles","previous_headings":"2 Customizing Prior Distributions","what":"Example 6: Stratified Survival Model","title":"Advanced Functionalities","text":"Scenario: model time--event outcome baseline hazard \\(h_0(t)\\) differs \\(\\text{country}\\). particularly important multi-regional trials regional differences standard care affect baseline risk.","code":"set.seed(123) n_patients <- 200 lambda_by_country <- c(US = 0.01, EU = 0.03) surv_data_strat <- data.frame(     id = 1:n_patients,     country = factor(sample(c(\"US\", \"EU\"), n_patients, replace = TRUE)),     trt = factor(sample(0:1, n_patients, replace = TRUE)),     age = rnorm(n_patients, 65, 10),     biomarker = factor(sample(c(\"Low\", \"High\"), n_patients, replace = TRUE)) ) lp <- (as.integer(surv_data_strat$trt)-1) * -0.6 + (surv_data_strat$age - 65) * 0.03 +       (as.integer(surv_data_strat$trt)-1) * (as.integer(surv_data_strat$biomarker) - 1) * -0.5 u <- runif(n_patients) lambda_vec <- lambda_by_country[surv_data_strat$country] gamma <- 1.5 # Weibull shape parameter true_event_time <- (-log(u) / (lambda_vec * exp(lp)))^(1/gamma) censoring_time <- 60 # Administrative censoring time surv_data_strat$event_status <- ifelse(true_event_time <= censoring_time, 1, 0) surv_data_strat$event_time <- pmin(true_event_time, censoring_time) # Model Fitting with Stratified Baseline Hazard fit_surv_stratified <- run_brms_analysis(   data = surv_data_strat,   response_formula_str = \"Surv(event_time, event_status) ~ trt\",   response_type = \"survival\",   unshrunk_prognostic_formula_str = \"~ age\",   shrunk_predictive_formula_str = \"~ biomarker:trt\",   stratification_formula_str = \"~ country\",   chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = \"cmdstanr\" ) #> Step 1: Preparing formula and data... #> Response type is 'survival'. Modeling the baseline hazard explicitly using bhaz(). #> Applying stratification: estimating separate baseline hazards by 'country'. #> Treatment 'trt' added to unshrunk prognostic terms by default. #> Auto-adding missing prognostic effect for interaction: biomarker #>  #> Step 2: Fitting the brms model... #> Using default priors for unspecified effects: #>   - unshrunk prognostic (b): normal(0, 5) #>   - shrunk predictive (b): horseshoe(1) #> Fitting brms model... #> Start sampling #> Running MCMC with 1 chain... #>  #> Chain 1 WARNING: There aren't enough warmup iterations to fit the  #> Chain 1          three stages of adaptation as currently configured.  #> Chain 1          Reducing each adaptation stage to 15%/75%/10% of  #> Chain 1          the given number of warmup iterations:  #> Chain 1            init_buffer = 15  #> Chain 1            adapt_window = 75  #> Chain 1            term_buffer = 10  #> Chain 1 finished in 7.7 seconds. #> Warning: 100 of 100 (100.0%) transitions hit the maximum treedepth limit of 10. #> See https://mc-stan.org/misc/warnings for details. #>  #> Analysis complete. strat_surv_summary <- summary_subgroup_effects(   brms_fit = fit_surv_stratified,   original_data = surv_data_strat,   trt_var = \"trt\",   response_type = \"survival\" # Auto-detects biomarker interaction ) #> --- Calculating specific subgroup effects... --- #> `subgroup_vars` set to 'auto'. Detecting from model interaction terms... #> ...detected subgroup variable(s): biomarker #> Step 1: Creating counterfactual datasets... #> ...setting interaction dummy variables for the 'all treatment' scenario. #> Step 2: Generating posterior predictions... #> ... (reconstructing baseline hazard and getting linear predictors)... #> ... model is stratified by 'country'. Reconstructing hazard for each stratum. #> Warning: Dropping 'draws_df' class as required metadata was removed. #> Warning: Dropping 'draws_df' class as required metadata was removed. #> Step 3: Calculating marginal effects... #> ... processing biomarker #> Done.  print(strat_surv_summary$estimates) #> # A tibble: 2 × 4 #>   Subgroup        Median CI_Lower CI_Upper #>   <chr>            <dbl>    <dbl>    <dbl> #> 1 biomarker: High  0.568    0.419    0.760 #> 2 biomarker: Low   0.364    0.261    0.522 plot(strat_surv_summary, title = \"Stratified Survival: Subgroup Effects (AHR)\") #> Preparing data for plotting... #> Generating plot... #> Done."},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Quickstart.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Quickstart","text":"bonsaiforest2 package consists 3 core functions typically called sequence: run_brms_analysis() - Prepares model formula fits Bayesian model using brms. summary_subgroup_effects() - Calculates marginal overall subgroup treatment effects. plot() - Creates forest plot summary object. example makes use Bayesian modeling, requires installation brms package working Stan installation (e.g., via cmdstanr).","code":"install.packages(\"brms\") install.packages(\"cmdstanr\") cmdstanr::install_cmdstan()"},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Quickstart.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The Data","title":"Quickstart","text":"use simulated example dataset representing clinical trial blood pressure. relevant endpoint change Systolic Blood Pressure (SBP) baseline (sbp_change). consider analysis model want find treatment effect (trt) sbp_change. model adjust baseline_sbp prognostic variable (predictor outcome) explore region comorbidity predictive variables (potential treatment effect modifiers). First, let’s load libraries create data.","code":"# Load the main package library(bonsaiforest2)  # Load other required packages library(brms) library(dplyr) # Create the example data set.seed(123) n_patients <- 200 continuous_data <- data.frame(   id = 1:n_patients,   sbp_change = rnorm(n_patients, mean = -5, sd = 10),   trt = sample(0:1, n_patients, replace = TRUE),   baseline_sbp = rnorm(n_patients, mean = 140, sd = 15),   region = factor(sample(c(\"NA\", \"EU\", \"APAC\"), n_patients, replace = TRUE)),   comorbidity = factor(sample(c(\"Yes\", \"No\"), n_patients, replace = TRUE, prob = c(0.4, 0.6))) )  # `bonsaiforest2` expects the treatment variable to be a factor continuous_data$trt <- factor(continuous_data$trt, levels = c(0, 1))  print(head(continuous_data)) #>   id sbp_change trt baseline_sbp region comorbidity #> 1  1 -10.604756   0     129.2714     NA          No #> 2  2  -7.301775   0     128.7097     EU         Yes #> 3  3  10.587083   0     125.9219   APAC         Yes #> 4  4  -4.294916   0     124.2123     EU          No #> 5  5  -3.707123   0     133.4426   APAC         Yes #> 6  6  12.150650   0     144.9677     NA          No"},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Quickstart.html","id":"run_brms_analysis","dir":"Articles","previous_headings":"","what":"run_brms_analysis()","title":"Quickstart","text":"run_brms_analysis() function first step. builds model formula fits brms model, applying shrinkage priors exploratory terms. Key Arguments: data: input data.frame. response_formula_str: Defines outcome main treatment effect (e.g., \"outcome ~ trt\"). response_type: \"continuous\", \"binary\", \"count\", \"survival\". shrunk_predictive_formula_str: Treatment interactions estimate shrinkage (e.g., \"~ region:trt + sex:trt\"). unshrunk_prognostic_formula_str: Main effects (treatment interactions) estimate without strong shrinkage (e.g., \"~ age\"). shrunk_prognostic_formula_str: Main effects estimate shrinkage. unshrunk_predictive_formula_str: Treatment interactions estimate without strong shrinkage (e.g., \"~ prespecified_marker:trt\"). prognostic_effect_priors, predictive_effect_priors: Lists specifying priors shrunk/unshrunk terms. stanvars: Optional object brms::stanvar() custom Stan code (e.g., hierarchical priors). ...: arguments passed directly brms::brm() (like chains, iter, cores). example, : Define response sbp_change ~ trt. Adjust baseline_sbp unshrunk prognostic variable. Explore region comorbidity shrunk predictive variables. also include ~ 1 shrunk predictive formula apply shrinkage overall treatment effect (intercept interactions).","code":"# iter and chains are set low for a quick example. # For a real analysis, use more iterations (e.g., iter = 2000). continuous_model_fit <- run_brms_analysis(   data = continuous_data,   response_formula_str = \"sbp_change ~ trt\",   response_type = \"continuous\",   unshrunk_prognostic_formula_str = \"~ baseline_sbp\",   # Shrink intercept (1), region interaction, and comorbidity interaction   shrunk_predictive_formula_str = \"~ 1 + region:trt + comorbidity:trt\",   chains = 1, iter = 200, warmup = 100, cores = 1,   refresh = 0, backend = \"cmdstanr\" # Use cmdstanr if available ) #> Running MCMC with 1 chain... #>  #> Chain 1 WARNING: There aren't enough warmup iterations to fit the  #> Chain 1          three stages of adaptation as currently configured.  #> Chain 1          Reducing each adaptation stage to 15%/75%/10% of  #> Chain 1          the given number of warmup iterations:  #> Chain 1            init_buffer = 15  #> Chain 1            adapt_window = 75  #> Chain 1            term_buffer = 10  #> Chain 1 finished in 2.3 seconds.  print(continuous_model_fit) #>  Family: gaussian  #>   Links: mu = identity  #> Formula: sbp_change ~ unprogeffect + shpredeffect  #>          unprogeffect ~ baseline_sbp + trt + region + comorbidity #>          shpredeffect ~ region_APAC_x_trt + region_EU_x_trt + region_NA_x_trt + comorbidity_No_x_trt + comorbidity_Yes_x_trt + 0 #>    Data: data (Number of observations: 200)  #>   Draws: 1 chains, each with iter = 200; warmup = 100; thin = 1; #>          total post-warmup draws = 100 #>  #> Regression Coefficients: #>                                    Estimate Est.Error l-95% CI u-95% CI Rhat #> unprogeffect_Intercept                -0.00      3.37    -6.31     6.31 1.18 #> unprogeffect_baseline_sbp             -0.04      0.02    -0.08     0.00 1.18 #> unprogeffect_trt                       1.44      1.52    -1.68     4.30 1.02 #> unprogeffect_regionEU                 -0.46      1.88    -4.09     3.78 1.05 #> unprogeffect_regionNA                 -1.09      1.67    -4.49     2.06 1.02 #> unprogeffect_comorbidityYes            1.12      1.76    -1.97     4.50 1.06 #> shpredeffect_region_APAC_x_trt        -0.37      1.30    -3.11     2.51 1.06 #> shpredeffect_region_EU_x_trt           0.57      1.51    -2.08     3.72 1.07 #> shpredeffect_region_NA_x_trt           0.34      1.49    -2.35     3.49 1.03 #> shpredeffect_comorbidity_No_x_trt      0.64      1.49    -2.07     4.47 1.07 #> shpredeffect_comorbidity_Yes_x_trt    -0.31      1.30    -3.08     2.05 0.99 #>                                    Bulk_ESS Tail_ESS #> unprogeffect_Intercept                    5       41 #> unprogeffect_baseline_sbp                 5       38 #> unprogeffect_trt                         84       34 #> unprogeffect_regionEU                    30       31 #> unprogeffect_regionNA                    50      117 #> unprogeffect_comorbidityYes              79      104 #> shpredeffect_region_APAC_x_trt          130       60 #> shpredeffect_region_EU_x_trt            167       77 #> shpredeffect_region_NA_x_trt             88      115 #> shpredeffect_comorbidity_No_x_trt        49       71 #> shpredeffect_comorbidity_Yes_x_trt      164      117 #>  #> Further Distributional Parameters: #>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> sigma     9.43      0.46     8.71    10.43 1.02      114       52 #>  #> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Quickstart.html","id":"summary_subgroup_effects","dir":"Articles","previous_headings":"","what":"summary_subgroup_effects()","title":"Quickstart","text":"next step use fitted model generate interpretable subgroup effects. done summary_subgroup_effects(). function uses G-computation estimate marginal treatment effect subgroup (e.g., “average effect patients ‘EU’ region?”), averaging covariates like baseline_sbp comorbidity. main inputs brms_fit object previous step original_data.","code":"continuous_summary <- summary_subgroup_effects(   brms_fit = continuous_model_fit,   original_data = continuous_data, # Pass the original data   trt_var = \"trt\",   response_type = \"continuous\"     # Must match fitting   # subgroup_vars = \"auto\" is the default and finds all interactions ) #> --- Calculating specific subgroup effects... --- #> `subgroup_vars` set to 'auto'. Detecting from model interaction terms... #> ...detected subgroup variable(s): region, comorbidity #> Step 1: Creating counterfactual datasets... #> ...setting interaction dummy variables for the 'all treatment' scenario. #> Step 2: Generating posterior predictions... #> ... (predicting expected outcomes)... #> Step 3: Calculating marginal effects... #> ... processing region #> ... processing comorbidity #> Done.  print(continuous_summary) #> $estimates #> # A tibble: 5 × 4 #>   Subgroup         Median CI_Lower CI_Upper #>   <chr>             <dbl>    <dbl>    <dbl> #> 1 region: APAC       1.38   -1.55      4.37 #> 2 region: EU         2.11   -1.23      5.85 #> 3 region: NA         2.17   -1.27      5.12 #> 4 comorbidity: No    2.18   -0.142     4.87 #> 5 comorbidity: Yes   1.31   -2.01      3.90 #>  #> $response_type #> [1] \"continuous\" #>  #> $ci_level #> [1] 0.95 #>  #> $trt_var #> [1] \"trt\" #>  #> attr(,\"class\") #> [1] \"subgroup_summary\""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Quickstart.html","id":"plot","dir":"Articles","previous_headings":"","what":"plot()","title":"Quickstart","text":"Finally, plot() function takes subgroup_summary object creates forest plot easy interpretation.  plot displays marginal treatment effect (mean difference sbp_change) overall population subgroup level. estimates “shrunk” towards overall effect, providing stable results fitting separate models subgroup.","code":"# Generate and display the plot plot(continuous_summary, title = \"Continuous: Subgroup Effects on SBP Change\") #> Preparing data for plotting... #> Generating plot... #> Done."},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Quickstart.html","id":"code","dir":"Articles","previous_headings":"","what":"Code","title":"Quickstart","text":"report code main workflow presented vignette.","code":"library(bonsaiforest2) library(brms) library(dplyr) library(ggplot2)  # --- 2. The Data --- set.seed(123) n_patients <- 200 continuous_data <- data.frame(   id = 1:n_patients,   sbp_change = rnorm(n_patients, mean = -5, sd = 10),   trt = sample(0:1, n_patients, replace = TRUE),   baseline_sbp = rnorm(n_patients, mean = 140, sd = 15),   region = factor(sample(c(\"NA\", \"EU\", \"APAC\"), n_patients, replace = TRUE)),   comorbidity = factor(sample(c(\"Yes\", \"No\"), n_patients, replace = TRUE, prob = c(0.4, 0.6))) ) continuous_data$trt <- factor(continuous_data$trt, levels = c(0, 1))   # --- 3. run_brms_analysis() --- # (Use iter = 2000, chains = 4 for a real analysis) continuous_model_fit <- run_brms_analysis(   data = continuous_data,   response_formula_str = \"sbp_change ~ trt\",   response_type = \"continuous\",   unshrunk_prognostic_formula_str = \"~ baseline_sbp\",   shrunk_predictive_formula_str = \"~ 1 + region:trt + comorbidity:trt\",   chains = 1, iter = 200, warmup = 100, cores = 1,   refresh = 0, backend = \"cmdstanr\" )   # --- 4. summary_subgroup_effects() --- continuous_summary <- summary_subgroup_effects(   brms_fit = continuous_model_fit,   original_data = continuous_data,   trt_var = \"trt\",   response_type = \"continuous\" )   # --- 5. plot() --- plot(continuous_summary, title = \"Continuous: Subgroup Effects on SBP Change\")"},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"scope-of-this-document","dir":"Articles","previous_headings":"","what":"Scope of this document","title":"Statistical Specifications","text":"document describes statistical methods implemented bonsaiforest2 R package Bayesian subgroup analysis continuous, binary, count, time--event outcomes randomized clinical trials (RCTs). package unable implementation global modeling approach (Wolbers et al. 2025), estimates main (prognostic) interaction (predictive) effects single model, One-variable-time (Wang et al. 2024), estimates interaction effects using different model subgrouping variable. core features described document : Prognostic (main) vs. Predictive (interaction) effects. Shrunk vs. Unshrunk coefficients, allowing exploratory terms penalized pre-specified terms . Advanced Shrinkage Priors: Supports state---art shrinkage priors, including Regularized Horseshoe (Piironen Vehtari 2017; Wolbers et al. 2025) R2D2 (Zhang et al. 2022), provide robust control false-positive findings identifying potential heterogeneity. Marginal Effect Estimation: Use standardization (G-computation) derive interpretable marginal subgroup treatment effects, average covariate distributions within subgroup (Wolbers et al. 2025). document structured follows: Section 2 provides conceptual introduction subgroup analysis challenges Bayesian shrinkage solution. Section 3 details statistical methodology, including notation, global one-variable time models, endpoint-specific likelihoods, prior specifications, standardization procedure. Section 4 maps statistical methods core functions bonsaiforest2 package.","code":""},{"path":[]},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"the-challenge-of-subgroup-analysis","dir":"Articles","previous_headings":"2 Introduction to Subgroup Analysis and Estimation","what":"The Challenge of Subgroup Analysis","title":"Statistical Specifications","text":"Exploratory subgroup analyses standard part RCT reporting, typically visualized forest plots assess consistency treatment effects. However, interpretation notoriously difficult due several statistical challenges: Low Power: Subgroups smaller sample sizes, leading low precision (wide confidence intervals) inability detect true, modest differences effect. Multiplicity: Examining many subgroups (e.g., 20 ) inflates risk false-positive findings. Investigators may focus extreme results, often spurious. Overfitting: Standard subgroup-specific estimates (fitting model data within subgroup) unbiased high variance, leading overestimation heterogeneity. led common recommendation overall treatment effect often reliable estimate subgroup estimate derived subgroup’s data alone.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"prognostic-vs--predictive-effects","dir":"Articles","previous_headings":"2 Introduction to Subgroup Analysis and Estimation","what":"Prognostic vs. Predictive Effects","title":"Statistical Specifications","text":"build meaningful model, crucial distinguish baseline variable relates outcome: Prognostic Effect: variable prognostic associated clinical outcome, regardless treatment received. describes natural course disease. model, main effect. Predictive Effect: variable predictive value modifies magnitude direction treatment’s effect. identifies heterogeneity. model, treatment--variable interaction. bonsaiforest2 built model types effects explicitly apply different modeling strategies (e.g., shrinkage) .","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"the-role-of-bayesian-shrinkage","dir":"Articles","previous_headings":"2 Introduction to Subgroup Analysis and Estimation","what":"The Role of Bayesian Shrinkage","title":"Statistical Specifications","text":"Bayesian shrinkage methods directly address challenges subgroup analysis providing principled compromise two extremes “pooling” (subgroup-specific estimates) “full pooling” (overall population estimate). compromise, often called partial pooling, achieved using hierarchical models. Subgroup effects assumed exchangeable (drawn common distribution). assumption allows subgroups “borrow strength” : Subgroups small sample sizes extreme results “shrunk” heavily toward overall mean, reducing variance. Subgroups large sample sizes strong evidence real effect shrunk less, allowing data dominate. results estimates better bias-variance trade-: accept small amount bias (pulling real effects slightly toward mean) exchange large reduction variance, leading lower overall error better control spurious findings.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"conditional-vs--marginal-estimands","dir":"Articles","previous_headings":"2 Introduction to Subgroup Analysis and Estimation","what":"Conditional vs. Marginal Estimands","title":"Statistical Specifications","text":"covariates included non-linear model (like logistic Cox model), resulting coefficients represent conditional effects. example, treatment effect effect patient specific set covariate values (e.g., reference values). problematic forest plots, want know marginal effect: “average treatment effect patients ‘Female’ subgroup, averaging different ages, regions, etc.?”. different subgroups different covariate distributions (e.g., age >= 65 subgroup different health status profile age < 65 group), conditional coefficients directly comparable. bonsaiforest2 solves using Standardization (G-computation) (wolbers2024shrinkage?). procedure correctly averages specific covariate distribution subgroup estimate valid marginal treatment effect, ensuring subgroups compared interpretable scale. (See Section 3.8 detailed explanation standardization performed package.)","code":""},{"path":[]},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"setting-and-notation","dir":"Articles","previous_headings":"3 Statistical Methodology","what":"Setting and Notation","title":"Statistical Specifications","text":"establish following notation global model: \\(= 1, \\dots, N\\): Index individual patients. \\(y_i\\): outcome patient \\(\\). consider variable can binary, count, continuous time--event endpoint. \\(s_i\\): binary treatment indicator (\\(s_i=1\\) treatment, \\(s_i=0\\) control). \\(l = 1, \\dots, L\\): Index overall subgroup level (e.g., “Male”, “Female”, “EU”, “USA”). \\(x_{il}\\): Indicator (0/1) patient \\(\\) belonging subgroup level \\(l\\) (used prognostic effects). \\(z_{il} = s_i \\cdot x_{il}\\): interaction treatment subgroup level \\(l\\) (used predictive effects). \\(u_{iv}\\): Value \\(v\\)-th additional non-subgroup covariate patient \\(\\). additional covariates don’t need binary categorical. \\(\\boldsymbol{\\mu}\\): \\(N \\times 1\\) vector expected outcomes. \\(g(\\cdot)\\): link function. Section x define used link function type endpoint. \\(\\boldsymbol{\\eta}\\): \\(N \\times 1\\) vector linear predictor.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"design-matrix-considerations","dir":"Articles","previous_headings":"3 Statistical Methodology","what":"Design Matrix Considerations","title":"Statistical Specifications","text":"critical implementation detail construction design matrix subgroup--treatment interactions. follow idea bonsaiforest library. treat prognostic effects predictive effects differently, serve different purposes model: prognostic effects : goal interpretability avoiding collinearity intercept. , standard dummy coding appropriate choice. J subgrouping variables, one level dropped reference, resulting L−J total columns subgroup main effects. predictive effects: goal treat subgroup levels symmetrically assumption exchangeability. Using one-hot encoding essential . ensures shrinkage prior pulls predictive effects toward common center without privileging reference level.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"the-principle-of-model-hierarchy","dir":"Articles","previous_headings":"3 Statistical Methodology","what":"The Principle of Model Hierarchy","title":"Statistical Specifications","text":"fundamental concept regression modeling principle model hierarchy (marginality). principle states model includes interaction term (e.g., :B), also include corresponding main effects (e.g., B). context bonsaiforest2, means subgrouping variable included predictive (.e., interaction treatment, like trt:subgroup) must also included prognostic (.e., main effect, subgroup). Including main effect ensures interaction term purely captures modification treatment effect, rather mix main prognostic effect interaction, leading stable interpretable model. bonsaiforest2 package enforces principle automatically. prepare_formula_model function checks main effect specified prognostic every variable included predictive term. , function automatically adds main effect list unshrunk prognostic terms ensure model hierarchy respected.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"the-global-model","dir":"Articles","previous_headings":"3 Statistical Methodology","what":"The Global Model","title":"Statistical Specifications","text":"package enables implementation global model (Wolbers et al. 2025) effects estimated single, comprehensive regression formula.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"full-model-equation","dir":"Articles","previous_headings":"3 Statistical Methodology > 3.4 The Global Model","what":"Full Model Equation","title":"Statistical Specifications","text":"Matrix form: model linear predictor, \\(\\boldsymbol{\\eta}\\), \\(N\\) patients given : \\[g(\\boldsymbol{\\mu}) = \\boldsymbol{\\eta} = \\underbrace{\\mathbf{X_p}\\boldsymbol{\\beta_{1,p}}}_{\\text{Penalized prognostic effects}} +\\underbrace{\\mathbf{X_n}\\boldsymbol{\\beta_{1,n}}}_{\\text{Non-penalized prognostic effects}} +\\underbrace{\\mathbf{Z_p}\\boldsymbol{\\beta_{2,p}}}_{\\text{Penalized predictive effects}} +\\] \\[ \\underbrace{\\mathbf{Z_n}\\boldsymbol{\\beta_{2,n}}}_{\\text{Non-penalized predictive effects}}+ \\underbrace{\\mathbf{U}\\boldsymbol{\\beta_{3}}}_{\\text{Extra prognostic effects}} \\] Bayesian hierarchical structure applied follows: Penalized Coefficients: \\(\\boldsymbol{\\beta_{1,p}}\\) \\(\\boldsymbol{\\beta_{2,p}}\\) given shrinkage priors. Non-Penalized Coefficients: \\(\\boldsymbol{\\beta_{1,n}}\\) \\(\\boldsymbol{\\beta_{2,n}}\\) given standard, weakly informative priors. Extra prognostic effects Coefficients: \\(\\boldsymbol{\\beta_3}\\) given standard, weakly informative priors. Components definition: \\(\\mathbf{X}= [\\mathbf{X_p} \\;\\;  \\mathbf{X}_n]\\) \\(N \\times M\\) design matrix prognostic effects. typically includes: intercept column. Section x discuss inclusion prior give intercept detail column main treatment effect. Columns prognostic effects subgroup level (using dummy coding, one reference level per factor dropped). prognostic effect contained \\(\\mathbf{X}_n\\) \\(\\mathbf{X}_p\\) depending want shrink effect. Example: Table 3.1: example design matrix global subgroup model. Note: M=1+1+L-J= 1 degree intercept+ 1 treatment effect + L (Number subgroups) - J(Number variables) get reference levels . \\(\\boldsymbol{\\beta_{1,p}}\\) \\(P \\times 1\\) vector coefficients prognostic effects want shrink. give shrinkage prior coefficients. \\(\\boldsymbol{\\beta_{1,n}}\\) \\((M-P) \\times 1\\) vector coefficients prognostic effects don’t want shrink. \\(\\mathbf{Z}= [\\mathbf{Z_p} \\;\\;  \\mathbf{Z}_n]\\) \\(N \\times L\\) design matrix predictive effects. columns represent interaction treatment \\(L\\) subgroup levels across subgrouping variables. matrix constructed without dropping reference level treat subgroups symmetrically. \\(\\boldsymbol{\\beta_{2,p}}\\) \\(R \\times 1\\) vector coefficients predictive effects want shrink. give shrinkage prior coefficients. \\(\\boldsymbol{\\beta_{2,n}}\\) \\((L-R) \\times 1\\) vector coefficients predictive effects don’t want shrink. \\(U\\) \\(N \\times V\\) design matrix extra variables want take account fitting model. also unpenalized. \\(\\boldsymbol{\\beta_3}\\) \\(V \\times 1\\) vector extra prognostic effects coefficients Linear form: make concrete, linear predictor single patient \\(\\) can written : \\[ \\eta_i = \\underbrace{\\beta_0 + \\beta_{\\text{treat}}s_i + \\underbrace{\\sum_{l=1}^{P} \\beta^l_{1,p}x^{il}_n}_\\text{penalized}+ \\underbrace{\\sum_{l=P+1}^{M}  \\beta^l_{1,n}x^{il}_n}_\\text{penalized}+\\underbrace{\\sum_{v=1}^{V} \\beta_{3}^vu^{iv}}_{\\text{Extra }}}_{\\text{Prognostic Effects}} + \\underbrace{\\underbrace{\\sum_{l=1}^{L-R} \\beta_{2,p}^l z_p^{il}}_{\\text{penalized }} + \\underbrace{\\sum_{l=L-R+1}^{L} \\beta_{2,n}^l z_n^{il}}_{\\text{penalized}} }_{\\text{Predictive effects}} \\] Note: See even \\(z^{il}=x^{il}\\cdot s^{}\\), prognostic effect predictive effect subgrouping variable may penalized , separate \\(x\\) \\(z\\) formula.","code":"# 1. Create your data as a data frame design_matrix_df <- data.frame(   Patient    = c(1, 2, 3, 4),   Intercept  = c(1, 1, 1, 1),   trt        = c(0, 1, 0, 1),   sexF       = c(0, 1, 1, 0),   regionUS   = c(0, 0, 1, 1),   regionAsia = c(0, 1, 0, 0) )  # 2. Use knitr::kable() to format and print the table knitr::kable(   design_matrix_df,   caption = \"An example design matrix for a global subgroup model.\",   align = c('l', 'c', 'c', 'c', 'c') # Align columns (l=left, c=center) ) # Manually creating the interaction matrix for clarity interaction_matrix <- data.frame(   Patient      = 1:6,   `trt:sexM`   = c(1, 0, 1, 1, 0, 0),   `trt:sexF`   = c(0, 1, 0, 0, 1, 1),   `trt:regionEU` = c(0, 1, 0, 0, 1, 0),   `trt:regionUS` = c(1, 0, 0, 1, 0, 0),   `trt:regionAsia` = c(0, 0, 1, 0, 0, 1) )  # Using knitr::kable for a nice output knitr::kable(   interaction_matrix,   align = 'c',   col.names = c(\"Patient\", \"trt x sexM\", \"trt x sexF\", \"trt x regionEU\", \"trt x regionUS\", \"trt x regionAsia\") )"},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"example","dir":"Articles","previous_headings":"3 Statistical Methodology > 3.4 The Global Model","what":"Example","title":"Statistical Specifications","text":"randomized, double-blind trial comparing new drug, DrugX, placebo patients hypertension. Primary Endpoint (\\(Y_{}\\)): Change baseline systolic blood pressure (SBP) mmHg 6 months. Age Group: <65 vs. ≥65 years. Sex: Male vs. Female. Kidney Function: eGFR <60 (impaired) vs. ≥60 (normal). Covariates: BaselineSBPᵢ, BMIᵢ, Smokerᵢ (binary). Global Model Shrinkage outcome assumed normally distributed: \\(Y_{} \\sim N(\\mu_{}, \\sigma^2)\\). linear predictor \\(\\mu_{}\\) modeled : \\[ \\mu_{} = \\underbrace{\\beta_0}_{\\text{Intercept}} + \\underbrace{\\beta_{\\text{treat}} \\cdot \\text{Treatment}_i}_{\\text{Main Trt Effect}} + \\underbrace{\\sum_{k=1}^{K} \\alpha_k \\cdot \\text{Subgroup}_{ik}}_{\\text{Prognostic Subgroup Effects}} + \\underbrace{\\sum_{k=1}^{K} \\gamma_k \\cdot (\\text{Subgroup}_{ik} \\cdot \\text{Treatment}_i)}_{\\text{Shrunken Predictive Effects}} + \\underbrace{\\sum_{j=1}^{J} \\delta_j \\cdot \\text{Covariate}_{ij}}_{\\text{Extra Prognostic effects}} \\] \\[ =\\underbrace{\\beta_0}_{\\text{Intercept}} + \\underbrace{\\beta_{\\text{treat}} \\cdot \\text{Treatment}_i}_{\\text{Main Trt Effect}} + \\underbrace{\\alpha_1 \\cdot \\text{Age Group}_i+\\alpha_2 \\cdot \\text{Sex}_i+\\alpha_3 \\cdot \\text{eGFR}_i}_{\\text{Prognostic Subgroup Effects}}+ \\] \\[ + \\underbrace{\\gamma_1 \\cdot (\\text{Age Group}_i\\cdot \\text{Treatment}_i)+\\gamma_2 \\cdot (\\text{Sex}_i\\cdot \\text{Treatment}_i)+\\gamma_3 \\cdot (\\text{eGFR}_i\\cdot \\text{Treatment}_i)}_{\\text{Predictive Effects}} + \\underbrace{\\delta_1 \\cdot \\text{BaselineSBP}_i+\\delta_2 \\cdot \\text{BMI}_i+\\delta_3 \\cdot \\text{Smoker}_i}_{\\text{Extra Prognostic effects}} \\]","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"one-variable-at-a-time-model","dir":"Articles","previous_headings":"3 Statistical Methodology","what":"One-Variable-at-a-Time Model","title":"Statistical Specifications","text":"one-variable---time model (Wang et al. 2024) Bayesian hierarchical model (BHM) improves upon standard subgroup analysis borrowing information across subgroup levels produce stable reliable estimates. Instead analyzing subgroup level isolation, analyzes levels within single subgrouping variable (e.g., age groups) together one model. example, variable Sex (levels Male Female), fit one hierarchical model. single model, treatment effects Male (\\(\\beta_{2,\\text{sex,male}}\\)) Female (\\(\\beta_{2,\\text{sex,female}}\\)) treated exchangeable linked common prior distribution. , completely separate hierarchical model fit variable Region.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"full-model-equation-1","dir":"Articles","previous_headings":"3 Statistical Methodology > 3.5 One-Variable-at-a-Time Model","what":"Full Model Equation","title":"Statistical Specifications","text":"given subgrouping variable \\(j\\), can specify flexible linear predictor allows covariate effects constant across levels \\(j\\), others allowed vary. Let’s partition patient-level covariates two sets: \\(\\mathbf{u}_i\\): vector covariates assumed constant prognostic effect across levels subgrouping variable \\(j\\). \\(\\mathbf{v}_i\\): vector covariates strong priori reason believe prognostic effect varies across levels \\(k\\) subgrouping variable \\(j\\). linear predictor patient \\(\\) level \\(k\\) variable \\(j\\) : \\[g(\\mu_{,j,k}) = \\beta_{1,j,k} + \\beta_{2,j,k}z_i + \\boldsymbol{\\beta}_{3,j}\\mathbf{u}_i + \\boldsymbol{\\beta}_{4,j,k}\\mathbf{v}_i\\] \\(\\beta_{2,j,k}\\): predictive effect level \\(k\\) variable \\(j\\). primary parameter interest shrinkage. \\(\\boldsymbol{\\beta}_{3,j}\\mathbf{u}_i\\): effect covariates assumed constant across levels. coefficient vector \\(\\boldsymbol{\\beta}_{3,j}\\) \\(k\\) subscript. \\(\\boldsymbol{\\beta}_{4,j,k}\\mathbf{v}_i\\): effect covariates assumed level-specific. coefficient vector \\(\\boldsymbol{\\beta}_{4,j,k}\\) \\(k\\) subscript, allowing effect different subgroup level. can seen interaction variable \\(x_j\\) \\(v_i\\). Note coefficients \\(\\boldsymbol{\\beta}_{3,j}\\) \\(\\boldsymbol{\\beta}_{4,j,k}\\) can use shrinkage standard priors depending prior beliefs.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"example-1","dir":"Articles","previous_headings":"3 Statistical Methodology > 3.5 One-Variable-at-a-Time Model","what":"Example","title":"Statistical Specifications","text":"Similarly example showed Global model. example Age Group variable, \\(k \\\\{ \\text{<65}, \\text{≥65} \\}\\). outcome patient age subgroup k : \\(Y_{ik} \\sim N(\\mu_{ik}, \\sigma_k^2)\\). linear predictor \\(\\mu_{ik}\\) : \\[ \\mu_{ik} = \\underbrace{\\beta_{1,k}}_{\\text{Subgroup Intercept}} + \\underbrace{\\beta_{2,k} \\cdot \\text{Treatment}_i}_{\\text{Predictive Effect}} + \\underbrace{\\delta_1 \\cdot \\text{BMI}_i + \\delta_2 \\cdot \\text{Smoker}_i}_{\\text{Constant Prognostic Effects}} + \\underbrace{\\delta_{3,k} \\cdot \\text{BaselineSBP}_i}_{\\text{Varying Prognostic Effect}} \\] , \\(\\beta_{1,k}\\) (subgroup-specific intercept) \\(\\beta_{2,k}\\) (subgroup-specific predictive effect) given hierarchical priors borrow information across age groups. example: \\(\\beta_{2,k} \\sim N(\\mu_2, \\tau_2^2)\\). effect Baseline SBP also allowed vary age group (\\(\\delta_{3,k}\\)), BMI Smoking effects assumed constant","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"sec-intercept","dir":"Articles","previous_headings":"3 Statistical Methodology","what":"The Logic of the Intercept","title":"Statistical Specifications","text":"intercept (\\(\\beta_0\\)) subject shrinkage (fixed effect within unprogeffect component), specifying prior requires care ensure model remains weakly informative without introducing bias numerical instability. Default Specification: default, bonsaiforest assigns weakly informative Normal prior centered 0 standard deviation 5: \\[ \\beta_0 \\sim \\mathcal{N}(0, 5^2) \\] choice aligned methodology Wolbers et al. (2025), standard deviation 5 log-hazard logit scale covers wide range plausible effect sizes (e.g., ratios 0.08 12) still penalizing extreme, unrealistic values. Linking Prior Scale Trial Design: principled choice, users can adjust scale parameter (\\(\\sigma_{prior}\\)) based assumptions made trial design sample size calculation phase. Recommendation: Set prior standard deviation multiple design parameter, \\(\\sigma_{prior} = 10 \\times \\sigma_{design}\\). ensures prior wide enough cover plausible range outcomes envisioned planning. Recommendation: default \\(\\mathcal{N}(0, 5^2)\\) generally appropriate, covers vast multiplicative range event rates. However, trial designed rare events (e.g., \\(< 0.01\\) events/year) frequent events, centering prior log anticipated event rate protocol (\\(\\mu_0 = \\log(\\lambda_{design})\\)) rather 0 can improve convergence. Recommendation: Use prior scaled Unit Information Standard Deviation (UISD), adhere default \\(\\sigma=5\\). variance 25 covers entire range realistic probabilities without concentrating mass deterministic outcomes (0 1). Special Case: Time--Event Endpoints. Cox proportional hazards models, intercept identifiable omitted linear predictor. Mechanism: intercept effectively absorbed non-parametric baseline hazard function, \\(h_0(t)\\). Implementation: brms backend handles automatically estimating baseline hazard (via bhaz()) rather fixed intercept parameter. Therefore, prior specification \\(\\beta_0\\) required survival models.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"sec-endpoint","dir":"Articles","previous_headings":"3 Statistical Methodology","what":"Endpoint-Specific Models","title":"Statistical Specifications","text":"package supports four primary endpoint types specifying appropriate likelihood link function \\(g(\\boldsymbol{\\mu}) = \\boldsymbol{\\eta}\\).","code":""},{"path":[]},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"default-priors","dir":"Articles","previous_headings":"3 Statistical Methodology > 3.8 Prior Specifications","what":"Default Priors","title":"Statistical Specifications","text":"priors specified, function applies following defaults (defined fit_brms_model code): Prognostic Shrunk: horseshoe(1) Prognostic Unshrunk: normal(0, 5) Prognostic Intercept: normal(0, 10) Predictive Shrunk: horseshoe(1) Predictive Unshrunk: normal(0, 5) Note: intercept prior applied response_type = \"survival\", Cox models global intercept.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"weakly-informative-priors-unshrunk-terms","dir":"Articles","previous_headings":"3 Statistical Methodology > 3.8 Prior Specifications","what":"Weakly Informative Priors (Unshrunk Terms)","title":"Statistical Specifications","text":"non-penalized coefficients (\\(\\boldsymbol{\\beta_{1,n}}, \\boldsymbol{\\beta_{2,n}}, \\boldsymbol{\\beta_{3}}\\)), use weakly informative priors aid computational stability without strongly influencing posterior. Default: normal(0, 10). common, weakly regularizing prior linear predictor scale. Users can specify , e.g., student_t(3, 0, 2.5).","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"regularized-horseshoe-prior-shrunk-terms","dir":"Articles","previous_headings":"3 Statistical Methodology > 3.8 Prior Specifications","what":"Regularized Horseshoe Prior (Shrunk Terms)","title":"Statistical Specifications","text":"default shrinkage prior bonsaiforest2, recommended excellent adaptive shrinkage properties (Wolbers et al. 2025; Piironen Vehtari 2017). Concept: global-local prior. infinitely tall spike zero (aggressively shrink noise) heavy tails (leave true, large signals unshrunk). Hierarchical Specification: \\[\\begin{aligned} \\beta_{2,l} &\\sim N(0, \\tau^2 \\tilde{\\lambda}_l^2) \\\\ \\tilde{\\lambda}_l^2 &= \\frac{c^2 \\lambda_l^2}{c^2 + \\tau^2 \\lambda_l^2} \\\\ \\lambda_l &\\sim C^+(0, 1) \\quad (\\text{Local shrinkage}) \\\\ \\tau &\\sim C^+(0, \\tau_0) \\quad (\\text{Global shrinkage}) \\\\ c^2 &\\sim \\text{Inverse-Gamma}(\\nu/2, \\nu s^2/2) \\end{aligned}\\] Hyperparameter Justification: package supports two ways set crucial global scale \\(\\tau_0\\): Fixed Default (scale_global): horseshoe(scale_global = 1). package default, robust, general-purpose choice (Wolbers et al. 2025). Elicited Prior (par_ratio): Sets \\(\\tau_0\\) based prior belief number effective (non-zero) subgroups, \\(p_{eff}\\), total \\(L\\) (Bornkamp 2025; Piironen Vehtari 2017). specified via \\(\\text{par\\_ratio} = \\frac{p_{eff}}{L - p_{eff}}\\). scales prior based sample size (\\(N\\)) expected sparsity. Regularized Horseshoe Implementation brms brms package implements Regularized Horseshoe prior using function horseshoe(...). regularization term (“slab”) added standard Horseshoe ensure robustness improve computational stability Stan. Horseshoe Function Key Arguments Horseshoe prior set using function call: Relationship Justification: \\(\\mathbf{brms}\\) function offers two primary ways set global shrinkage level, controls overall sparsity model: Fixed Global Scale: Using \\(\\mathbf{scale\\_global}\\) argument, often set \\(\\mathbf{1.0}\\) general-purpose default. value internally multiplied residual standard deviation (\\(\\sigma\\)) autoscale = TRUE. Elicited Global Scale (Recommended): Using \\(\\mathbf{par\\_ratio}\\) argument, allows user specify prior belief sparsity model (.e., expected number true non-zero coefficients, \\(p_{eff}\\)). recommended approach accounts number coefficients \\(L\\) sample size \\(N\\) determine optimal \\(\\tau_0\\). Choosing \\(\\mathbf{scale\\_global}\\) \\(\\mathbf{par\\_ratio}\\): choice \\(\\tau_0\\) (controlled \\(\\mathbf{scale\\_global}\\) \\(\\mathbf{par\\_ratio}\\)) crucial, sets overall magnitude shrinkage. Fixed Default (\\(\\mathbf{scale\\_global=1}\\)): Use : want simple, robust, general-purpose prior without explicit sparsity knowledge. Caveat: May result insufficient shrinkage true number non-zero coefficients small. Elicited Sparsity (\\(\\mathbf{par\\_ratio}\\)): Calculation: \\(\\text{par\\_ratio} = \\frac{p_{eff}}{L - p_{eff}}\\), \\(p_{eff}\\) expected number non-zero coefficients \\(L\\) total number coefficients. Use : strong prior belief number relevant effects. generally preferred adaptive shrinkage scales \\(\\tau_0\\) appropriately. Recommendation: \\(\\mathbf{scale\\_global=1}\\) quick default, specifying \\(\\mathbf{par\\_ratio}\\) based expert knowledge expected sparsity theoretically sound adaptive method setting global shrinkage scale.","code":"horseshoe(df = 1, scale_global = 1, df_global = 1, scale_slab = 2, df_slab = 4, par_ratio = NULL, autoscale = TRUE, main = FALSE)"},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"r2d2-prior-shrunk-terms","dir":"Articles","previous_headings":"3 Statistical Methodology > 3.8 Prior Specifications","what":"R2D2 Prior (Shrunk Terms)","title":"Statistical Specifications","text":"Concept: prior uniquely derived first placing prior model’s coefficient determination, \\(R^2\\), quantifies proportion variance explained predictors. arguably intuitive specifying priors directly coefficients. Hierarchical Specification (Marginal Version): \\[ \\begin{aligned} \\beta_{2,l} &\\sim DE(\\sigma \\sqrt{\\phi_l \\omega / 2}) \\quad (\\text{Double-Exponential/Laplace kernel}) \\\\ \\boldsymbol{\\phi} &= (\\phi_1, \\dots, \\phi_L) \\sim \\text{Dirichlet}(a_\\pi, \\dots, a_\\pi) \\quad (\\text{Local shrinkage}) \\\\ \\omega &\\sim \\text{Beta-Prime}(, b) \\quad (\\text{Global shrinkage}) \\end{aligned} \\] equivalent assuming proportion variance explained interaction terms follows \\(R^2 = \\frac{\\omega}{1+\\omega} \\sim \\text{Beta}(,b)\\). Justification Hyperparameters: Zhang et al. (2022) provide clear guidance. fully automatic approach set \\(b=0.5\\) achieve Cauchy-like heavy tails. concentration parameter \\(a_\\pi\\) controls sparsity. smaller \\(a_\\pi\\) (e.g., 0.2) implies higher shrinkage, concentrating prior variance fewer coefficients, larger \\(a_\\pi\\) (e.g., 0.5) spreads variance evenly, implying lower shrinkage. Default Recommendation: Set \\(b=0.5\\) offer options user based desired shrinkage strength: High Shrinkage: \\(a_\\pi=0.2\\) Low Shrinkage: \\(a_\\pi=0.5\\) R2D2 Prior Implementation brms brms package implements prior using function R2D2(...), providing high-level parametrization intuitive setting parameters \\(\\), \\(b\\), \\(a_\\pi\\) directly. function translates desired \\(\\mathbf{R^2}\\) properties shrinkage strength underlying prior distribution’s parameters. R2D2 Function Key Arguments R2D2 prior set using function call: Relationship Justification: brms function parameters directly related justified hierarchical parameters: \\(\\mathbf{cons\\_D2}\\) parameter direct counterpart sparsity parameter \\(\\mathbf{a_{\\pi}}\\). default recommendation \\(\\mathbf{cons\\_D2 = 0.5}\\) corresponds precisely \\(\\mathbf{a_{\\pi}=0.5}\\) low shrinkagesetting. \\(\\mathbf{mean\\_R2}\\) \\(\\mathbf{prec\\_R2}\\) arguments define \\(\\text{Beta}(,b)\\) prior \\(R^2\\), : \\[= \\text{mean_R2} \\times \\text{prec_R2}\\] \\[b = (1 - \\text{mean_R2}) \\times \\text{prec_R2}\\] choice \\(\\mathbf{prec\\_R2=2}\\) (default) alongside \\(\\mathbf{mean\\_R2=0.5}\\) results \\(=1\\) \\(b=1\\), Uniform prior \\(R^2 \\sim \\text{Beta}(1, 1)\\), representing maximally weak prior belief global fit. essential \\(\\mathbf{b=0.5}\\) setting Cauchy-like heavy tails (preventing -shrinkage) implicitly handled R2D2 function’s underlying structure require manual specification. Choosing \\(\\mathbf{mean\\_R2}\\) \\(\\mathbf{prec\\_R2}\\) : Choosing parameters involves quantifying prior knowledge model’s overall predictive power observing data. define \\(\\text{Beta}(,b)\\) distribution \\(R^2\\). Choosing \\(\\mathbf{mean\\_R2}\\) (Prior Expected \\(R^2\\)): sets center prior belief. Default (0.5): Use strong prior knowledge. implies neutral expectation fixed effects explain half variance. Informative Low (e.g., 0.1 0.3): Use expect weak noisy relationship. Informative High (e.g., 0.7 0.9): Use expect highly predictive model based strong prior evidence. Choosing \\(\\mathbf{prec\\_R2}\\) (Prior Confidence \\(R^2\\)): determines concentration certainty Beta prior around chosen \\(\\text{mean_R2}\\). Resulting Beta Parameters (\\(\\text{mean_R2}=0.5\\)) Recommendation: Default \\(\\mathbf{mean\\_R2 = 0.5}\\) \\(\\mathbf{prec\\_R2 = 2}\\) provides flexible, weakly informative setting \\(R^2\\), generally recommended unless strong prior knowledge dictates otherwise.","code":"R2D2(mean_R2 = 0.5, prec_R2 = 2, cons_D2 = 0.5, autoscale = TRUE, main = FALSE)"},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"normal-hierarchical-prior-for-one-variable-at-a-time-model","dir":"Articles","previous_headings":"3 Statistical Methodology > 3.8 Prior Specifications","what":"Normal Hierarchical Prior (for One-Variable-at-a-Time Model)","title":"Statistical Specifications","text":"standard hierarchical model subgroup analysis, assumes treatment effects levels within subgrouping variable drawn common normal distribution. ’s less complex Horseshoe R2D2 priors provides effective shrinkage, especially number subgroup levels small. Hierarchical Specification: given subgrouping variable \\(j\\) levels \\(k=1, \\dots, K_j\\): \\[\\begin{aligned} \\beta_{2,j,k} &\\sim \\mathcal{N}(\\mu_{2,j}, \\tau^2_{2,j}) \\quad (\\text{Level-specific treatment effects}) \\\\     \\mu_{2,j} &\\sim \\mathcal{N}(0, s^2) \\quad (\\text{Common mean effect}) \\\\ \\tau_{2,j} &\\sim \\text{Half-Normal}() \\quad (\\text{-subgroup heterogeneity}) \\end{aligned}     \\] Justification Hyperparameters: key setting scale parameter Half-Normal prior -subgroup standard deviation, \\(\\tau_{2,j}\\), controls degree shrinkage. recommended Bornkamp (2025), can linked planned treatment effect ( \\(\\delta_{plan}\\)) trial protocol, making prior choice interpretable consistent across different endpoints. choice implies prior plausible difference treatment effects two subgroups.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"estimation-mcmc","dir":"Articles","previous_headings":"3 Statistical Methodology","what":"Estimation (MCMC)","title":"Statistical Specifications","text":"joint posterior distribution parameters complex closed-form solution. use Markov Chain Monte Carlo (MCMC) methods draw samples distribution. Specifically, package uses -U-Turn Sampler (NUTS), efficient variant Hamiltonian Monte Carlo (HMC), implemented Stan via brms package. output set posterior samples (e.g., 4000 draws) representing joint posterior distribution.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"sec-standardization","dir":"Articles","previous_headings":"3 Statistical Methodology","what":"Standardization for Marginal Effects (G-computation)","title":"Statistical Specifications","text":"obtain interpretable marginal effects subgroup, package implements standardization (G-computation) procedure. process repeated MCMC draw generate full posterior distribution marginal effect. single MCMC draw, step--step process : Select Parameters: Take one draw joint posterior distribution model parameters (\\(\\boldsymbol{\\beta}\\)’s, \\(\\sigma\\), \\(\\phi\\), etc.). Create Counterfactuals: every patient \\(\\) original dataset, create two scenarios: Scenario : Patient \\(\\)’s covariates, treatment \\(s_i=0\\) (Control). Scenario B: Patient \\(\\)’s covariates, treatment \\(s_i=1\\) (Treatment). Predict Outcomes: Use model formula parameters Step 1 predict outcome every patient Scenario (\\(\\hat{\\mu}_{,0}\\)) Scenario B (\\(\\hat{\\mu}_{,1}\\)). Average within Subgroups: subgroup interest \\(l\\) (e.g., “Female”): Calculate average predicted outcome control: \\(\\hat{\\mu}_{l,0} = \\text{mean}(\\hat{\\mu}_{,0})\\) \\(\\) \\(x_{il}=1\\). Calculate average predicted outcome treatment: \\(\\hat{\\mu}_{l,1} = \\text{mean}(\\hat{\\mu}_{,1})\\) \\(\\) \\(x_{il}=1\\). Calculate Effect Measure: Compute marginal effect subgroup \\(l\\) averaged predictions. depends endpoint type: Continuous: Mean Difference = \\(\\hat{\\mu}_{l,1} - \\hat{\\mu}_{l,0}\\). Binary: Odds Ratio = \\(\\frac{\\hat{\\mu}_{l,1} / (1 - \\hat{\\mu}_{l,1})}{\\hat{\\mu}_{l,0} / (1 - \\hat{\\mu}_{l,0})}\\) (\\(\\hat{\\mu}\\) predicted probability). Count: Rate Ratio = \\(\\hat{\\mu}_{l,1} / \\hat{\\mu}_{l,0}\\) (\\(\\hat{\\mu}\\) predicted rate). Time--Event: Average Hazard Ratio (AHR). complex, requires predicting full survival curve \\(S_i(t)\\) patient. marginal survival curves \\(\\hat{S}_{l,0}(t)\\) \\(\\hat{S}_{l,1}(t)\\) calculated, AHR computed , marginal curves may proportional. Repeat: process (Steps 1-5) repeated MCMC draws, yielding full posterior distribution (e.g., 4000 values) marginal effect subgroup. final point estimate (median) 95% credible interval taken distribution.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/articles/Statistical_Specifications.html","id":"sec-functions","dir":"Articles","previous_headings":"","what":"Mapping of Statistical Methods to bonsaiforest2 Functions","title":"Statistical Specifications","text":"section connects statistical methodology (Section 3) core package functions. run_brms_analysis() Maps : Sections 3.2 (Global Model), 3.3 (Endpoints), 3.4 (Priors), 3.5 (Estimation). constructs design matrices \\(\\mathbf{X_n}, \\mathbf{X_p}, \\mathbf{Z_n}, \\mathbf{Z_p}, \\mathbf{U}\\) based formula string arguments (e.g., unshrunk_prognostic_formula_str, shrunk_predictive_formula_str). assigns specified priors (e.g., predictive_effect_priors = list(shrunk = \"horseshoe(par_ratio = 0.1)\")). builds passes full brmsformula data brms::brm() run Stan MCMC sampler. handles stratification via stratification_formula_str argument, adds terms like bhaz(country) sigma ~ country brmsformula. summary_subgroup_effects() Maps : Section 3.6 (Standardization / G-computation). takes fitted brms_fit object (containing posterior samples) original_data. automatically detects subgroups specified model (uses subgroup_vars argument). iterates posterior sample, generates counterfactual predictions, averages within subgroups, calculates marginal effect measure (e.g., AHR, ) based response_type. returns subgroup_summary object containing posterior distributions marginal effects. plot() Maps : Final visualization Section 3.6 results. Action: method subgroup_summary objects. takes summarized posterior distributions (median 95% CrI) overall subgroup effects generates forest plot.","code":""},{"path":[]},{"path":"https://openpharma.github.io/bonsaiforest2/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Miriam Pedrera Gomez. Author, maintainer. Isaac Gravestock. Author. Marcel Wolbers. Author.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pedrera Gomez M, Gravestock , Wolbers M (2025). bonsaiforest2: Flexible Bayesian Shrinkage Based Forest Plots. R package version 0.1.0, https://openpharma.github.io/bonsaiforest2/.","code":"@Manual{,   title = {bonsaiforest2: Flexible Bayesian Shrinkage Based Forest Plots},   author = {Miriam {Pedrera Gomez} and Isaac Gravestock and Marcel Wolbers},   year = {2025},   note = {R package version 0.1.0},   url = {https://openpharma.github.io/bonsaiforest2/}, }"},{"path":"https://openpharma.github.io/bonsaiforest2/index.html","id":"bonsaiforest2-","dir":"","previous_headings":"","what":"Flexible Bayesian Shrinkage Based Forest Plots","title":"Flexible Bayesian Shrinkage Based Forest Plots","text":"goal bonsaiforest2 simplify fitting interpreting Bayesian models subgroup analysis clinical trials. leverages power brms package : Distinguish prognostic (baseline predictors) predictive (treatment effect modifiers) factors. Apply differential shrinkage priors (like Horseshoe R2D2) explore subgroup effects robustly. Calculate interpretable marginal treatment effects using counterfactual approach. Generate publication-ready forest plots.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Flexible Bayesian Shrinkage Based Forest Plots","text":"can install development version bonsaiforest2 GitLab repository:","code":"# install.packages(\"remotes\")  remotes::install_github(\"openpharma/bonsaiforest2\")"},{"path":"https://openpharma.github.io/bonsaiforest2/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Flexible Bayesian Shrinkage Based Forest Plots","text":"basic example showing main workflow: fitting simple continuous outcome model shrinkage subgroup interaction.  Summarized Effects:","code":"library(bonsaiforest2) library(brms) # Needed for backend  # 1. Minimal data setup set.seed(123) n <- 50 # Small n for README example sim_data_readme <- data.frame(   outcome = rnorm(n),   trt = factor(sample(0:1, n, replace = TRUE)),   age = rnorm(n, 50, 10),   region = factor(sample(c(\"A\", \"B\"), n, replace = TRUE)) )  # 2. Fit a simple model (use very few iterations for speed!) # Shrink the treatment:region interaction fit <- run_brms_analysis(   data = sim_data_readme,   response_formula_str = \"outcome ~ trt\",   response_type = \"continuous\",   unshrunk_prognostic_formula_str = \"~ age\",     # Adjust for age   shrunk_predictive_formula_str = \"~ trt:region\", # Explore region interaction   chains = 1, iter = 50, warmup = 25, refresh = 0, # Keep it FAST   backend = \"cmdstanr\" # Optional: Specify backend if needed )  # 3. Summarize marginal effects (will auto-detect 'region') effect_summary <- summary_subgroup_effects(   brms_fit = fit,   original_data = sim_data_readme,   trt_var = \"trt\",   response_type = \"continuous\" )  # 4. Plot the results plot(effect_summary) # Display plot #> # A tibble: 3 × 4 #>   Subgroup  Median CI_Lower CI_Upper #>   <chr>      <dbl>    <dbl>    <dbl> #> 1 Overall    0.346  -0.0276    0.837 #> 2 region: A  0.260  -0.569     0.776 #> 3 region: B  0.457   0.0312    1.45"},{"path":"https://openpharma.github.io/bonsaiforest2/reference/bonsaiforest2-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bonsaiforest2: bonsaiforest2 — bonsaiforest2-package","title":"bonsaiforest2: bonsaiforest2 — bonsaiforest2-package","text":"(maybe one line). Continuation lines indented.","code":""},{"path":[]},{"path":"https://openpharma.github.io/bonsaiforest2/reference/bonsaiforest2-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bonsaiforest2: bonsaiforest2 — bonsaiforest2-package","text":"Maintainer: Miriam Pedrera Gomez miriam.pedrera_gomez@roche.com Authors: Isaac Gravestock isaac.gravestock@roche.com","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/estimate_subgroup_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Marginal Subgroup Treatment Effects — estimate_subgroup_effects","title":"Estimate Marginal Subgroup Treatment Effects — estimate_subgroup_effects","text":"function uses counterfactual, marginal approach based posterior predictive distribution. averages covariates provide robust estimates subgroup-specific effects. estimation follows steps: Creates two counterfactual datasets based model data: one     subjects receive \"treatment\" one receive \"control\". Generates posterior predictions (e.g., `brms::posterior_epred`)     scenarios. Calculates treatment effect (e.g., difference ratio)     subject posterior draw. Averages individual-level effects within subgroup     produce final marginal subgroup estimates.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/estimate_subgroup_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Marginal Subgroup Treatment Effects — estimate_subgroup_effects","text":"","code":"estimate_subgroup_effects(   brms_fit,   original_data,   trt_var,   subgroup_vars = \"auto\",   response_type = c(\"continuous\", \"binary\", \"count\", \"survival\"),   ndraws = NULL )"},{"path":"https://openpharma.github.io/bonsaiforest2/reference/estimate_subgroup_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Marginal Subgroup Treatment Effects — estimate_subgroup_effects","text":"brms_fit fitted `brmsfit` object `fit_brms_model()` `run_brms_analysis()`. original_data `data.frame` containing original data processed `prepare_formula_model()`. essential correctly identifying original subgroup factor levels. trt_var character string specifying name treatment variable. subgroup_vars character vector subgroup variable names found `original_data`. set `\"auto\"` (default), function attempts automatically identify subgroup variables model's interaction terms. response_type type outcome variable. One \"binary\", \"count\", \"continuous\", \"survival\". determines scale effect (e.g., risk difference, rate ratio). ndraws integer specifying number posterior draws use. `NULL` (default), available draws used.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/estimate_subgroup_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Marginal Subgroup Treatment Effects — estimate_subgroup_effects","text":"`data.frame` (tibble) row corresponds subgroup (\"Overall\" effect), providing estimated marginal effect posterior summaries (e.g., `mean`, `sd`, `q2.5`, `q97.5`).","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/estimate_subgroup_effects.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Marginal Subgroup Treatment Effects — estimate_subgroup_effects","text":"post-processing function estimates marginal treatment effects specified subgroups fitted `brmsfit` object.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/estimate_subgroup_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Marginal Subgroup Treatment Effects — estimate_subgroup_effects","text":"","code":"if (require(\"brms\") && require(\"survival\")) {   # 1. Create Sample Data   set.seed(123)   n <- 100   sim_data <- data.frame(     time = round(runif(n, 1, 100)),     status = sample(0:1, n, replace = TRUE),     trt = sample(0:1, n, replace = TRUE),     age = rnorm(n, 50, 10),     region = sample(c(\"A\", \"B\"), n, replace = TRUE),     subgroup = sample(c(\"S1\", \"S2\", \"S3\"), n, replace = TRUE)   )   sim_data$trt <- factor(sim_data$trt, levels = c(0, 1))   sim_data$region <- as.factor(sim_data$region)   sim_data$subgroup <- as.factor(sim_data$subgroup)    # 2. Run the full analysis   # \\donttest{   full_fit <- run_brms_analysis(     data = sim_data,     response_formula_str = \"Surv(time, status) ~ trt\",     response_type = \"survival\",     shrunk_predictive_formula_str = \"~ trt:subgroup\",     unshrunk_prognostic_formula_str = \"~ age\",     shrunk_prognostic_formula_str = \"~ region\",     chains = 1, iter = 50, warmup = 10, refresh = 0   )    # 3. Estimate subgroup effects   # Note: We pass the original `sim_data`, not the processed model data.   effects <- estimate_subgroup_effects(     brms_fit = full_fit,     original_data = sim_data,     trt_var = \"trt\",     subgroup_vars = c(\"subgroup\", \"region\"),     response_type = \"survival\"   )    print(effects)   # } } #> Loading required package: brms #> Loading required package: Rcpp #> Loading 'brms' package (version 2.23.0). Useful instructions #> can be found by typing help('brms'). A more detailed introduction #> to the package is available through vignette('brms_overview'). #>  #> Attaching package: ‘brms’ #> The following object is masked from ‘package:stats’: #>  #>     ar #> Loading required package: survival #>  #> Attaching package: ‘survival’ #> The following object is masked from ‘package:brms’: #>  #>     kidney #> Step 1: Preparing formula and data... #> Response type is 'survival'. Modeling the baseline hazard explicitly using bhaz(). #> Treatment 'trt' added to unshrunk prognostic terms by default. #> Auto-adding missing prognostic effect for interaction: subgroup #>  #> Step 2: Fitting the brms model... #> Using default priors for unspecified effects: #>   - shrunk prognostic (b): horseshoe(1) #>   - unshrunk prognostic (b): normal(0, 5) #>   - shrunk predictive (b): horseshoe(1) #> Fitting brms model... #> Compiling Stan program... #> Start sampling #> Warning: There were 30 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: There were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See #> https://mc-stan.org/misc/warnings.html#bfmi-low #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is 2.3, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #>  #> Analysis complete. #> Step 1: Creating counterfactual datasets... #> ...setting interaction dummy variables for the 'all treatment' scenario. #> Step 2: Generating posterior predictions... #> ... (reconstructing baseline hazard and getting linear predictors)... #> Warning: Dropping 'draws_df' class as required metadata was removed. #> Step 3: Calculating marginal effects... #> ... processing subgroup #> ... processing region #> Done. #> $estimates #> # A tibble: 5 × 4 #>   Subgroup     Median CI_Lower CI_Upper #>   <chr>         <dbl>    <dbl>    <dbl> #> 1 subgroup: S1  1.01     0.976    1.04  #> 2 subgroup: S2  0.927    0.893    0.944 #> 3 subgroup: S3  1.07     1.03     1.10  #> 4 region: A     1.02     0.978    1.04  #> 5 region: B     1.01     0.976    1.03  #>  #> $draws #> # A tibble: 40 × 5 #>    `subgroup: S1` `subgroup: S2` `subgroup: S3` `region: A` `region: B` #>             <dbl>          <dbl>          <dbl>       <dbl>       <dbl> #>  1          0.978          0.895           1.04       0.984       0.980 #>  2          0.978          0.895           1.04       0.984       0.980 #>  3          0.987          0.903           1.05       0.990       0.987 #>  4          0.987          0.903           1.05       0.990       0.987 #>  5          0.987          0.903           1.05       0.990       0.987 #>  6          0.976          0.893           1.03       0.978       0.976 #>  7          0.976          0.893           1.03       0.978       0.976 #>  8          0.976          0.893           1.03       0.978       0.976 #>  9          0.976          0.893           1.03       0.978       0.976 #> 10          0.976          0.893           1.03       0.978       0.976 #> # ℹ 30 more rows #>"},{"path":"https://openpharma.github.io/bonsaiforest2/reference/fit_brms_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Bayesian Hierarchical Model using brms — fit_brms_model","title":"Fit a Bayesian Hierarchical Model using brms — fit_brms_model","text":"function serves wrapper fit Bayesian model using `brms` package. uses formula data prepared `prepare_formula_model` simplifies process assigning complex priors different non-linear components model.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/fit_brms_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Bayesian Hierarchical Model using brms — fit_brms_model","text":"","code":"fit_brms_model(   prepared_model,   predictive_effect_priors = list(),   prognostic_effect_priors = list(),   stanvars = NULL,   ... )"},{"path":"https://openpharma.github.io/bonsaiforest2/reference/fit_brms_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Bayesian Hierarchical Model using brms — fit_brms_model","text":"prepared_model list object returned `prepare_formula_model()`. must contain elements `formula`, `data`, `response_type`. predictive_effect_priors named list elements `shrunk` /`unshrunk` containing priors predictive effects. prognostic_effect_priors named list elements `shrunk`, `unshrunk`, /`intercept` containing priors prognostic effects. stanvars object created `brms::stanvar()` add custom Stan code. ... Additional arguments passed directly `brms::brm()`.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/fit_brms_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Bayesian Hierarchical Model using brms — fit_brms_model","text":"fitted `brmsfit` object.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/fit_brms_model.html","id":"prior-specification","dir":"Reference","previous_headings":"","what":"Prior Specification","title":"Fit a Bayesian Hierarchical Model using brms — fit_brms_model","text":"Priors prognostic predictive effects provided named lists. makes code explicit prevents errors. example: `prognostic_effect_priors = list(shrunk = \"horseshoe(1)\", unshrunk = \"normal(0, 5)\", intercept = \"normal(0, 10)\")`. function accepts prior definitions character strings (e.g., `\"normal(0, 1)\"`) full `brmsprior` objects, useful defining complex hierarchical parameter-specific priors.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/fit_brms_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Bayesian Hierarchical Model using brms — fit_brms_model","text":"","code":"if (require(\"brms\") && require(\"survival\")) {   # 1. Create Sample Data   set.seed(123)   n <- 100   sim_data <- data.frame(     time = round(runif(n, 1, 100)),     status = sample(0:1, n, replace = TRUE),     trt = sample(0:1, n, replace = TRUE),     age = rnorm(n, 50, 10),     region = sample(c(\"A\", \"B\"), n, replace = TRUE),     subgroup = sample(c(\"S1\", \"S2\", \"S3\"), n, replace = TRUE)   )   sim_data$trt <- factor(sim_data$trt, levels = c(0, 1))   sim_data$region <- as.factor(sim_data$region)   sim_data$subgroup <- as.factor(sim_data$subgroup)    # 2. Prepare the formula and data   prepared_model <- prepare_formula_model(     data = sim_data,     response_formula_str = \"Surv(time, status) ~ trt\",     shrunk_predictive_formula_str = \"~ trt:subgroup\",     unshrunk_prognostic_formula_str = \"~ age\",     shrunk_prognostic_formula_str = \"~ region\",     response_type = \"survival\",     stratification_formula_str = \"~ region\"   )    # 3. Fit the model   # \\donttest{   fit <- fit_brms_model(     prepared_model = prepared_model,     # Note: intercept prior is not needed for survival models     prognostic_effect_priors = list(shrunk = \"horseshoe(1)\", unshrunk = \"normal(0, 2)\"),     predictive_effect_priors = list(shrunk = \"horseshoe(1)\"),     chains = 1, iter = 50, warmup = 10, refresh = 0 # For a quick example   )    print(fit)  # } } #> Response type is 'survival'. Modeling the baseline hazard explicitly using bhaz(). #> Applying stratification: estimating separate baseline hazards by 'region'. #> Treatment 'trt' added to unshrunk prognostic terms by default. #> Auto-adding missing prognostic effect for interaction: subgroup #> Fitting brms model... #> Compiling Stan program... #> Start sampling #> Warning: There were 33 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is 2.06, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> Warning: Parts of the model have not converged (some Rhats are > 1.05). Be careful when analysing the results! We recommend running more iterations and/or setting stronger priors. #> Warning: There were 33 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #>  Family: cox  #>   Links: mu = log  #> Formula: time | cens(1 - status) + bhaz(Boundary.knots = c(0.02, 99.98), knots = c(24, 46, 69), intercept = FALSE, gr = region) ~ unprogeffect + shprogeffect + shpredeffect  #>          unprogeffect ~ age + trt + subgroup + 0 #>          shprogeffect ~ region + 0 #>          shpredeffect ~ subgroup_S1_x_trt + subgroup_S2_x_trt + subgroup_S3_x_trt + 0 #>    Data: data (Number of observations: 100)  #>   Draws: 1 chains, each with iter = 50; warmup = 10; thin = 1; #>          total post-warmup draws = 40 #>  #> Regression Coefficients: #>                                Estimate Est.Error l-95% CI u-95% CI Rhat #> unprogeffect_age                   0.01      0.00     0.01     0.02 1.89 #> unprogeffect_trt                  -0.07      0.01    -0.09    -0.06 1.50 #> unprogeffect_subgroupS1            0.75      0.00     0.75     0.76 1.94 #> unprogeffect_subgroupS2           -1.03      0.01    -1.04    -1.01 1.94 #> unprogeffect_subgroupS3           -0.53      0.00    -0.53    -0.53 1.50 #> shprogeffect_regionA              -0.01      0.00    -0.01     0.00 1.50 #> shprogeffect_regionB              -1.55      0.01    -1.57    -1.53 1.50 #> shpredeffect_subgroup_S1_x_trt     0.06      0.00     0.06     0.06 1.94 #> shpredeffect_subgroup_S2_x_trt    -0.03      0.00    -0.04    -0.03 1.32 #> shpredeffect_subgroup_S3_x_trt     0.13      0.01     0.11     0.13 1.94 #>                                Bulk_ESS Tail_ESS #> unprogeffect_age                      9       NA #> unprogeffect_trt                      2       NA #> unprogeffect_subgroupS1               9       NA #> unprogeffect_subgroupS2               2       NA #> unprogeffect_subgroupS3               2       NA #> shprogeffect_regionA                  2       NA #> shprogeffect_regionB                 14        7 #> shpredeffect_subgroup_S1_x_trt        9       NA #> shpredeffect_subgroup_S2_x_trt       14        7 #> shpredeffect_subgroup_S3_x_trt        2       NA #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://openpharma.github.io/bonsaiforest2/reference/plot.subgroup_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Marginal Subgroup Treatment Effects — plot.subgroup_summary","title":"Plot Marginal Subgroup Treatment Effects — plot.subgroup_summary","text":"Creates forest plot `subgroup_summary` object. version uses simplified labels format \"variable: level\".","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/plot.subgroup_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Marginal Subgroup Treatment Effects — plot.subgroup_summary","text":"","code":"# S3 method for class 'subgroup_summary' plot(x, x_lab = NULL, title = NULL, ...)"},{"path":"https://openpharma.github.io/bonsaiforest2/reference/plot.subgroup_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Marginal Subgroup Treatment Effects — plot.subgroup_summary","text":"x object class `subgroup_summary`. x_lab character string x-axis label. `NULL`, default chosen based `response_type`. title character string plot title. ... Additional arguments (currently used).","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/plot.subgroup_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Marginal Subgroup Treatment Effects — plot.subgroup_summary","text":"`ggplot` object representing forest plot.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/plot.subgroup_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Marginal Subgroup Treatment Effects — plot.subgroup_summary","text":"","code":"if (require(\"brms\") && require(\"survival\")) {   # 1. Create Sample Data (as in previous examples)   set.seed(123)   n <- 100   sim_data <- data.frame(     time = round(runif(n, 1, 100)),     status = sample(0:1, n, replace = TRUE),     trt = sample(0:1, n, replace = TRUE),     age = rnorm(n, 50, 10),     region = sample(c(\"A\", \"B\"), n, replace = TRUE),     subgroup = sample(c(\"S1\", \"S2\", \"S3\"), n, replace = TRUE)   )   sim_data$trt <- factor(sim_data$trt, levels = c(0, 1))   sim_data$region <- as.factor(sim_data$region)   sim_data$subgroup <- as.factor(sim_data$subgroup)    # 2. Run the full analysis (fast example)   # \\donttest{   full_fit <- run_brms_analysis(     data = sim_data,     response_formula_str = \"Surv(time, status) ~ trt\",     response_type = \"survival\",     shrunk_predictive_formula_str = \"~ trt:subgroup\",     chains = 1, iter = 50, warmup = 10, refresh = 0   )    # 3. Get the summary object   eff_summary <- summary_subgroup_effects(     brms_fit = full_fit,     original_data = sim_data,     trt_var = \"trt\",     response_type = \"survival\",     subgroup_vars = c(\"subgroup\", \"region\")   )    # 4. Plot the object   plot(eff_summary, title = \"My Subgroup Analysis\")   # } } #> Step 1: Preparing formula and data... #> Response type is 'survival'. Modeling the baseline hazard explicitly using bhaz(). #> Treatment 'trt' added to unshrunk prognostic terms by default. #> Auto-adding missing prognostic effect for interaction: subgroup #>  #> Step 2: Fitting the brms model... #> Using default priors for unspecified effects: #>   - unshrunk prognostic (b): normal(0, 5) #>   - shrunk predictive (b): horseshoe(1) #> Fitting brms model... #> Compiling Stan program... #> Start sampling #> Warning: The largest R-hat is 1.21, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #>  #> Analysis complete. #> --- Calculating specific subgroup effects... --- #> Step 1: Creating counterfactual datasets... #> ...setting interaction dummy variables for the 'all treatment' scenario. #> Step 2: Generating posterior predictions... #> ... (reconstructing baseline hazard and getting linear predictors)... #> Warning: Dropping 'draws_df' class as required metadata was removed. #> Step 3: Calculating marginal effects... #> ... processing subgroup #> ... processing region #> Done. #> Preparing data for plotting... #> Generating plot... #> Done."},{"path":"https://openpharma.github.io/bonsaiforest2/reference/prepare_formula_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","title":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","text":"function serves powerful pre-processor building complex Bayesian models `brms` package. automates construction multi-part, non-linear formula classifying covariates four distinct categories: unshrunk prognostic, shrunk prognostic, unshrunk predictive, shrunk predictive.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/prepare_formula_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","text":"","code":"prepare_formula_model(   data,   response_formula_str,   shrunk_predictive_formula_str = NULL,   unshrunk_prognostic_formula_str = NULL,   unshrunk_predictive_formula_str = NULL,   shrunk_prognostic_formula_str = NULL,   response_type = c(\"binary\", \"count\", \"continuous\", \"survival\"),   stratification_formula_str = NULL )"},{"path":"https://openpharma.github.io/bonsaiforest2/reference/prepare_formula_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","text":"data data.frame containing necessary variables. response_formula_str character string response part, e.g., \"outcome ~ trt\", count models \"n_events + offset(log(days)) ~ trt\" survival models \"Surv(time,status) ~ trt\". shrunk_predictive_formula_str Predictive terms shrunk ('shpredeffect'). typically interactions treatment variable. unshrunk_prognostic_formula_str Prognostic terms shrunk ('unprogeffect'). main effects assumed important. unshrunk_predictive_formula_str Predictive terms shrunk ('unpredeffect'). shrunk_prognostic_formula_str Prognostic terms shrunk ('shprogeffect'). main effects regularization desired. response_type type outcome variable. One \"binary\", \"count\", \"continuous\", \"survival\". stratification_formula_str formula string specifying stratification variable, e.g., \"~ strata_var\".","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/prepare_formula_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","text":"list three elements: `formula` (`brmsformula` object),   `data` (modified data.frame), `response_type` (  character string response type).","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/prepare_formula_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","text":"classification allows applying differential shrinkage (regularization) different parts model. function also prepares corresponding data, including automatic creation dummy variables predictive effects (interactions).","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/prepare_formula_model.html","id":"key-features","dir":"Reference","previous_headings":"","what":"Key Features","title":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","text":"Multi-Part Formula Construction: generates `brmsformula`     object four distinct linear components (`unprogeffect`,     `shprogeffect`, `unpredeffect`, `shpredeffect`), combined     non-linear model. allows assigning different priors     component. Automated Interaction Handling: Predictive terms (e.g.,     `~ trt:subgroup`) automatically expanded. level     `subgroup` variable, new dummy column created dataset,     representing interaction, simplifying modeling treatment effect     heterogeneity. Hierarchical Integrity: predictive term like     `trt:subgroup` specified, function automatically ensures     corresponding prognostic (main) effect `subgroup` included model,     adhering principle model hierarchy. Intelligent Defaults: main treatment variable automatically     added unshrunk prognostic term specified elsewhere. also     provides warnings resolves overlaps term accidentally specified     multiple categories.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/prepare_formula_model.html","id":"survival-model-details-robust-spline-knot-calculation-","dir":"Reference","previous_headings":"","what":"Survival Model Details (Robust Spline Knot Calculation)","title":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","text":"survival models (`response_type = \"survival\"`), function explicitly models baseline hazard using B-splines via `brms::bhaz()`. implements highly robust method calculating spline knots ensure stability: Boundary Definition: first establishes boundary knots taking     range unique event times adding small buffer. creates     \"safe\" interval placing internal knots. Internal Knot Placement: calculates internal knots using     quantiles event times fall strictly within boundary knots.     prevents knots placed exact edges data,     can cause numerical instability. Fallback Sparse Data: unique event     times calculate quantile-based knots, gracefully falls back placing     evenly spaced knots within defined boundaries.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/prepare_formula_model.html","id":"data-transformation","dir":"Reference","previous_headings":"","what":"Data Transformation","title":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","text":"critical note function returns modified `data.frame`. treatment variable converted integer (0/1), new columns interaction terms created. returned `data` object used subsequent call `brms::brm()`, original data.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/prepare_formula_model.html","id":"stratification","dir":"Reference","previous_headings":"","what":"Stratification","title":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","text":"`stratification_formula_str` argument allows estimating certain parameters separately different groups. behavior depends `response_type`: survival: Estimates separate baseline hazard function (`bhaz`)     level stratification variable. continuous: Models residual standard deviation (`sigma`) varying     across levels stratification variable. count: Models overdispersion parameter (`shape`) varying     across levels stratification variable.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/prepare_formula_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare a Multi-Part brms Formula and Corresponding Data — prepare_formula_model","text":"","code":"if (require(\"brms\") && require(\"survival\")) {   # 1. Create Sample Data   set.seed(123)   n <- 100   sim_data <- data.frame(     time = round(runif(n, 1, 100)),     status = sample(0:1, n, replace = TRUE),     trt = sample(0:1, n, replace = TRUE),     age = rnorm(n, 50, 10),     region = sample(c(\"A\", \"B\"), n, replace = TRUE),     subgroup = sample(c(\"S1\", \"S2\", \"S3\"), n, replace = TRUE)   )   sim_data$trt <- factor(sim_data$trt, levels = c(0, 1))   sim_data$region <- as.factor(sim_data$region)   sim_data$subgroup <- as.factor(sim_data$subgroup)    # 2. Run the function   prepared_model <- prepare_formula_model(     data = sim_data,     response_formula_str = \"Surv(time, status) ~ trt\",     shrunk_predictive_formula_str = \"~ trt:subgroup\",     unshrunk_prognostic_formula_str = \"~ age\",     shrunk_prognostic_formula_str = \"~ region\",     response_type = \"survival\",     stratification_formula_str = \"~ region\"   )    # 3. View the results   print(prepared_model$formula)   print(head(prepared_model$data)) } #> Response type is 'survival'. Modeling the baseline hazard explicitly using bhaz(). #> Applying stratification: estimating separate baseline hazards by 'region'. #> Treatment 'trt' added to unshrunk prognostic terms by default. #> Auto-adding missing prognostic effect for interaction: subgroup #> time | cens(1 - status) + bhaz(Boundary.knots = c(0.02, 99.98), knots = c(24, 46, 69), intercept = FALSE, gr = region) ~ unprogeffect + shprogeffect + shpredeffect  #> unprogeffect ~ age + trt + subgroup + 0 #> shprogeffect ~ region + 0 #> shpredeffect ~ subgroup_S1_x_trt + subgroup_S2_x_trt + subgroup_S3_x_trt + 0 #>   time status trt      age region subgroup subgroup_S1_x_trt subgroup_S2_x_trt #> 1   29      0   1 57.87739      B       S2                 0                 1 #> 2   79      1   1 57.69042      B       S1                 1                 0 #> 3   41      1   1 53.32203      B       S3                 0                 0 #> 4   88      0   0 39.91623      B       S3                 0                 0 #> 5   94      1   1 48.80547      A       S3                 0                 0 #> 6    6      1   1 47.19605      A       S2                 0                 1 #>   subgroup_S3_x_trt #> 1                 0 #> 2                 0 #> 3                 1 #> 4                 0 #> 5                 1 #> 6                 0"},{"path":"https://openpharma.github.io/bonsaiforest2/reference/run_brms_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a Full Bayesian Hierarchical Model Analysis — run_brms_analysis","title":"Run a Full Bayesian Hierarchical Model Analysis — run_brms_analysis","text":"high-level wrapper function streamlines entire process preparing fitting complex Bayesian hierarchical model `brms`.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/run_brms_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a Full Bayesian Hierarchical Model Analysis — run_brms_analysis","text":"","code":"run_brms_analysis(   data,   response_formula_str,   response_type,   shrunk_predictive_formula_str = NULL,   unshrunk_prognostic_formula_str = NULL,   unshrunk_predictive_formula_str = NULL,   shrunk_prognostic_formula_str = NULL,   stratification_formula_str = NULL,   predictive_effect_priors = list(),   prognostic_effect_priors = list(),   stanvars = NULL,   ... )"},{"path":"https://openpharma.github.io/bonsaiforest2/reference/run_brms_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a Full Bayesian Hierarchical Model Analysis — run_brms_analysis","text":"data data.frame containing necessary variables. response_formula_str character string response part, e.g., \"outcome ~ trt\" \"Surv(time, status) ~ trt\". response_type type outcome variable. One \"binary\", \"count\", \"continuous\", \"survival\". shrunk_predictive_formula_str Predictive terms shrunk ('shpredeffect'). E.g., \"~ trt:subgroup1\". unshrunk_prognostic_formula_str Prognostic terms shrunk ('unprogeffect'). E.g., \"~ age + sex\". unshrunk_predictive_formula_str Predictive terms shrunk ('unpredeffect'). E.g., \"~ trt:important_subgroup\". shrunk_prognostic_formula_str Prognostic terms shrunk ('shprogeffect'). E.g., \"~ region + center\". stratification_formula_str formula string specifying stratification variable, e.g., \"~ strata_var\". predictive_effect_priors named list elements `shrunk` /`unshrunk` containing priors predictive effects. Can strings `brmsprior` objects. E.g., `list(shrunk = \"horseshoe(1)\", unshrunk = \"normal(0, 5)\")`. prognostic_effect_priors named list elements `shrunk`, `unshrunk` /`intercept` containing priors prognostic effects. E.g., `list(shrunk = \"horseshoe(1)\", unshrunk = \"normal(0, 10)\")`. stanvars object created `brms::stanvar()` add custom Stan code, necessary hierarchical priors. ... Additional arguments passed directly `brms::brm()` (e.g., `chains`, `iter`, `cores`, `backend`).","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/run_brms_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a Full Bayesian Hierarchical Model Analysis — run_brms_analysis","text":"fitted `brmsfit` object.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/run_brms_analysis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run a Full Bayesian Hierarchical Model Analysis — run_brms_analysis","text":"function main user-facing entry point. first calls `prepare_formula_model` build `brmsformula` process data, passes results `fit_brms_model` run analysis.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/run_brms_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a Full Bayesian Hierarchical Model Analysis — run_brms_analysis","text":"","code":"if (require(\"brms\") && require(\"survival\")) {   # 1. Create Sample Data   set.seed(123)   n <- 100   sim_data <- data.frame(     time = round(runif(n, 1, 100)),     status = sample(0:1, n, replace = TRUE),     trt = sample(0:1, n, replace = TRUE),     age = rnorm(n, 50, 10),     region = sample(c(\"A\", \"B\"), n, replace = TRUE),     subgroup = sample(c(\"S1\", \"S2\", \"S3\"), n, replace = TRUE)   )   sim_data$trt <- factor(sim_data$trt, levels = c(0, 1))   sim_data$region <- as.factor(sim_data$region)   sim_data$subgroup <- as.factor(sim_data$subgroup)    # 2. Run the full analysis   # We use \\donttest{} because fitting a model can be slow   # and is not suitable for automated CRAN checks.   # \\donttest{   full_fit <- run_brms_analysis(     data = sim_data,     response_formula_str = \"Surv(time, status) ~ trt\",     response_type = \"survival\",     shrunk_predictive_formula_str = \"~ trt:subgroup\",     unshrunk_prognostic_formula_str = \"~ age\",     shrunk_prognostic_formula_str = \"~ region\",     stratification_formula_str = \"~ region\",     prognostic_effect_priors = list(       shrunk = \"normal(0, 1)\",       unshrunk = \"normal(0, 5)\"     ),     predictive_effect_priors = list(       shrunk = \"horseshoe(1)\"     ),     chains = 1, iter = 50, warmup = 10, refresh = 0 # For a quick example   )    print(full_fit)   # } } #> Step 1: Preparing formula and data... #> Response type is 'survival'. Modeling the baseline hazard explicitly using bhaz(). #> Applying stratification: estimating separate baseline hazards by 'region'. #> Treatment 'trt' added to unshrunk prognostic terms by default. #> Auto-adding missing prognostic effect for interaction: subgroup #>  #> Step 2: Fitting the brms model... #> Fitting brms model... #> Compiling Stan program... #> Start sampling #> Warning: There were 9 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is 1.84, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #>  #> Analysis complete. #> Warning: Parts of the model have not converged (some Rhats are > 1.05). Be careful when analysing the results! We recommend running more iterations and/or setting stronger priors. #> Warning: There were 9 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #>  Family: cox  #>   Links: mu = log  #> Formula: time | cens(1 - status) + bhaz(Boundary.knots = c(0.02, 99.98), knots = c(24, 46, 69), intercept = FALSE, gr = region) ~ unprogeffect + shprogeffect + shpredeffect  #>          unprogeffect ~ age + trt + subgroup + 0 #>          shprogeffect ~ region + 0 #>          shpredeffect ~ subgroup_S1_x_trt + subgroup_S2_x_trt + subgroup_S3_x_trt + 0 #>    Data: data (Number of observations: 100)  #>   Draws: 1 chains, each with iter = 50; warmup = 10; thin = 1; #>          total post-warmup draws = 40 #>  #> Regression Coefficients: #>                                Estimate Est.Error l-95% CI u-95% CI Rhat #> unprogeffect_age                   0.01      0.01    -0.00     0.02 1.32 #> unprogeffect_trt                  -0.07      0.26    -0.58     0.13 1.09 #> unprogeffect_subgroupS1            0.35      0.69    -1.02     0.89 1.49 #> unprogeffect_subgroupS2           -0.56      0.31    -1.14    -0.10 1.48 #> unprogeffect_subgroupS3           -0.35      0.18    -0.49     0.02 1.50 #> shprogeffect_regionA               0.09      0.11    -0.14     0.21 1.21 #> shprogeffect_regionB              -0.02      0.40    -1.50     0.53 1.10 #> shpredeffect_subgroup_S1_x_trt     0.13      0.34    -0.54     0.43 1.22 #> shpredeffect_subgroup_S2_x_trt     0.25      0.22     0.09     0.64 1.26 #> shpredeffect_subgroup_S3_x_trt     0.14      0.06    -0.08     0.21 1.04 #>                                Bulk_ESS Tail_ESS #> unprogeffect_age                      3       17 #> unprogeffect_trt                     11       21 #> unprogeffect_subgroupS1               2       19 #> unprogeffect_subgroupS2               2       17 #> unprogeffect_subgroupS3               2       21 #> shprogeffect_regionA                  4       12 #> shprogeffect_regionB                 14       17 #> shpredeffect_subgroup_S1_x_trt        4       21 #> shpredeffect_subgroup_S2_x_trt        3       21 #> shpredeffect_subgroup_S3_x_trt       12       17 #>  #> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS #> and Tail_ESS are effective sample size measures, and Rhat is the potential #> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"https://openpharma.github.io/bonsaiforest2/reference/summary_subgroup_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Summary of Marginal Subgroup Treatment Effects — summary_subgroup_effects","title":"Create a Summary of Marginal Subgroup Treatment Effects — summary_subgroup_effects","text":"function orchestrates calls `estimate_subgroup_effects` generate complete summary table. calculates overall marginal effect effects specific subgroups.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/summary_subgroup_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Summary of Marginal Subgroup Treatment Effects — summary_subgroup_effects","text":"","code":"summary_subgroup_effects(   brms_fit,   original_data,   trt_var,   response_type = c(\"binary\", \"count\", \"continuous\", \"survival\"),   subgroup_vars = \"auto\" )"},{"path":"https://openpharma.github.io/bonsaiforest2/reference/summary_subgroup_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Summary of Marginal Subgroup Treatment Effects — summary_subgroup_effects","text":"brms_fit fitted `brmsfit` object. original_data original `data.frame` used model fitting (processing `prepare_formula_model`). trt_var name treatment variable (coded 0/1). response_type type outcome variable. One \"binary\", \"count\", \"continuous\", \"survival\". subgroup_vars character vector subgrouping variable names. Defaults \"auto\", detects subgroups model. Set `NULL` get overall effect.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/summary_subgroup_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Summary of Marginal Subgroup Treatment Effects — summary_subgroup_effects","text":"object class `subgroup_summary`, list containing: estimates `tibble` combining overall subgroup-specific   effect estimates. response_type specified response type. ci_level credible interval level (hard-coded 0.95). trt_var name treatment variable.","code":""},{"path":"https://openpharma.github.io/bonsaiforest2/reference/summary_subgroup_effects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Summary of Marginal Subgroup Treatment Effects — summary_subgroup_effects","text":"","code":"if (require(\"brms\") && require(\"survival\")) {   # 1. Create Sample Data   set.seed(123)   n <- 100   sim_data <- data.frame(     time = round(runif(n, 1, 100)),     status = sample(0:1, n, replace = TRUE),     trt = sample(0:1, n, replace = TRUE),     age = rnorm(n, 50, 10),     region = sample(c(\"A\", \"B\"), n, replace = TRUE),     subgroup = sample(c(\"S1\", \"S2\", \"S3\"), n, replace = TRUE)   )   sim_data$trt <- factor(sim_data$trt, levels = c(0, 1))   sim_data$region <- as.factor(sim_data$region)   sim_data$subgroup <- as.factor(sim_data$subgroup)    # 2. Run the full analysis   # \\donttest{   full_fit <- run_brms_analysis(     data = sim_data,     response_formula_str = \"Surv(time, status) ~ trt\",     response_type = \"survival\",     shrunk_predictive_formula_str = \"~ trt:subgroup\",     unshrunk_prognostic_formula_str = \"~ age\",     shrunk_prognostic_formula_str = \"~ region\",     chains = 1, iter = 50, warmup = 10, refresh = 0   )    # 3. Get the summary   # This function calls estimate_subgroup_effects internally   eff_summary <- summary_subgroup_effects(     brms_fit = full_fit,     original_data = sim_data,     trt_var = \"trt\",     response_type = \"survival\",     subgroup_vars = c(\"subgroup\", \"region\")   )    print(eff_summary)   # } } #> Step 1: Preparing formula and data... #> Response type is 'survival'. Modeling the baseline hazard explicitly using bhaz(). #> Treatment 'trt' added to unshrunk prognostic terms by default. #> Auto-adding missing prognostic effect for interaction: subgroup #>  #> Step 2: Fitting the brms model... #> Using default priors for unspecified effects: #>   - shrunk prognostic (b): horseshoe(1) #>   - unshrunk prognostic (b): normal(0, 5) #>   - shrunk predictive (b): horseshoe(1) #> Fitting brms model... #> Compiling Stan program... #> Start sampling #> Warning: There were 30 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: There were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See #> https://mc-stan.org/misc/warnings.html#bfmi-low #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is 2.3, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #>  #> Analysis complete. #> --- Calculating specific subgroup effects... --- #> Step 1: Creating counterfactual datasets... #> ...setting interaction dummy variables for the 'all treatment' scenario. #> Step 2: Generating posterior predictions... #> ... (reconstructing baseline hazard and getting linear predictors)... #> Warning: Dropping 'draws_df' class as required metadata was removed. #> Step 3: Calculating marginal effects... #> ... processing subgroup #> ... processing region #> Done. #> $estimates #> # A tibble: 5 × 4 #>   Subgroup     Median CI_Lower CI_Upper #>   <chr>         <dbl>    <dbl>    <dbl> #> 1 subgroup: S1  1.01     0.976    1.04  #> 2 subgroup: S2  0.927    0.893    0.944 #> 3 subgroup: S3  1.07     1.03     1.10  #> 4 region: A     1.02     0.978    1.04  #> 5 region: B     1.01     0.976    1.03  #>  #> $response_type #> [1] \"survival\" #>  #> $ci_level #> [1] 0.95 #>  #> $trt_var #> [1] \"trt\" #>  #> attr(,\"class\") #> [1] \"subgroup_summary\""}]
