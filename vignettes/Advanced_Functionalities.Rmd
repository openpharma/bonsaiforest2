---
title: "Advanced Functionalities"
author: Miriam Pedrera Gomez, Isaac Gravestock, and Marcel Wolbers
output: 
  bookdown::html_document2:
    toc: true
    toc_depth: 4
    number_sections: true
    citation_package: natbib
    base_format: rmarkdown::html_vignette
bibliography: "references.bib"
link-citations: true   
linkcolor: blue
pkgdown:
  as_is: true
vignette: >
  %\VignetteIndexEntry{Advanced Functionalities}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>"
)
```

This vignette demonstrates advanced functionalities for Bayesian shrinkage estimation, including specifying an **offset for count data**, customizing **prior distributions**, and using **stratification** to handle heterogeneity in nuisance parameters.

# Handling Exposure in Count Outcomes with Offsets

For count data (like disease exacerbations or event rates), the observed count often depends on the **exposure time** or **follow-up time**. Using an **offset** variable is the standard statistical method to properly account for this time variation by modeling the event **rate** (count per unit time) instead of the raw count.

In `bonsaiforest2`, you can include the offset directly in the `response_formula_str` using the standard `brms` syntax: `outcome + offset(log_time) ~ predictors`.

## Example 1: Count Outcome with Offset (Disease Exacerbations)

This scenario models exacerbation counts using a Negative Binomial distribution and explicitly accounts for the patient's exposure time.

*Scenario*: Modeling exacerbation counts. Adjust for `baseline_severity` (unshrunk) and many exploratory `biomarkers` (shrunk). No interaction terms (overall treatment effect only).

```{r}
# Data Simulation 
set.seed(789)
library(bonsaiforest2)
n_patients <- 150
biomarker_data <- as.data.frame(matrix(rnorm(n_patients * 10), ncol = 10))
names(biomarker_data) <- paste0("biomarker_", 1:10)
count_data <- data.frame(
  exacerbation_count = rnbinom(n_patients, size = 1.5, mu = 3),
  medication = sample(0:1, n_patients, replace = TRUE),
  baseline_severity = rnorm(n_patients, 10, 2),
  log_exposure_time = log(runif(n_patients, 0.5, 1.5)) # Example offset
)
count_data <- cbind(count_data, biomarker_data)
count_data$medication <- factor(count_data$medication, levels = c(0, 1))

# Create formula string for all biomarkers (Prognostic effects only here)
shrunk_prog_str <- paste("~", paste(names(biomarker_data), collapse = " + "))
```

```{r}
# Model Fitting with Offset
# For count models, sigma_ref is typically set to 1 (used as reference scale for priors)

count_model_fit <- run_brms_analysis(
  data = count_data,
  # Include offset(log_exposure_time) directly in the response formula
  response_formula = exacerbation_count + offset(log_exposure_time) ~ medication,
  response_type = "count",
  unshrunk_terms_formula = ~ 1 + baseline_severity,
  shrunk_prognostic_formula = as.formula(shrunk_prog_str),
  sigma_ref = 1,  # Standard value for count models
  chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = "cmdstanr"
)
```

# Customizing Prior Distributions


The choice of prior is central to Bayesian shrinkage. `bonsaiforest2` provides sensible defaults, but it allows for full customization using the `prognostic_effect_priors` and `predictive_effect_priors` arguments.

## Prior Specification Mechanics

**NEW API:** Priors are now specified using separate parameters for each component, with a **required** `sigma_ref` parameter that serves as the reference scale.

| Prior Component | Parameter Name | Default Prior | Notes |
|:-----------------|:-----------------|:-----------------|:------------------|
| **Reference Scale** | `sigma_ref` | **REQUIRED** | Must be user-specified: `sd(outcome)` for continuous/count, typically `1` for binary/survival |
| **Intercept** | `intercept_prior` | `normal(mean(outcome), 5*sigma_ref)` | Automatically centered at observed mean |
| **Unshrunk Terms** | `unshrunk_prior` | `normal(0, 5*sigma_ref)` | Weakly informative |
| **Shrunk Prognostic** | `shrunk_prognostic_prior` | `horseshoe(scale_global = sigma_ref)` | Strong shrinkage |
| **Shrunk Predictive** | `shrunk_predictive_prior` | `horseshoe(scale_global = sigma_ref)` | Strong shrinkage |

**Key Feature:** You can use `sigma_ref` in prior expressions (e.g., `"normal(0, 2.5 * sigma_ref)"`) and the actual value will be automatically substituted.

### Prior Recommendations for Non-Shrunk Terms

For non-shrunk (fixed) effects, choosing a **weakly informative prior** is critical to stabilize the model without unduly influencing the results. A robust strategy is to scale the priors based on the **standard deviation (SD)** of the outcome variable.

$$\sigma_{outcome} = \text{SD}(\text{Outcome})$$

| Parameter | Recommended Prior Scale | Justification |
|:-----------------------|:-----------------------|:-----------------------|
| **Intercept** | $\text{Normal}(0, 10 \times \sigma_{outcome})$ | Wide enough to cover the range of outcomes if all predictors are zero. |
| **Unshrunk Prognostic** | $\text{Normal}(0, \sigma_{outcome})$ | Assumes a typical coefficient's impact is roughly comparable to the magnitude of the outcome's variability. |

## Practical Examples of Prior Setting
To provide a functional example, we will generate a **synthetic dataset** that mirrors the structure of the **Tirzepatide (SURPASS-2) trial** case study described in Wang et al. (2024). This study used a **continuous endpoint** (change in HbA1c), which fits perfectly with your code snippet calculating the standard deviation (`sd`).

### Dataset Generation and Model Preparation (Synthetic SURPASS-2)

This dataset mimics a clinical trial comparing a Treatment (Tirzepatide) vs. Control (Semaglutide), looking at subgroups defined by **Sex**, **Race**, and **Age Group**.

```{r}
# Prerequisites: Ensure packages used by your function are loaded
library(survival) # For Surv()
library(brms)     # For brmsformula objects
library(bonsaiforest2)

# 1. Create Sample Data (matching your @examples section)
set.seed(123)
n <- 100
sim_data <- data.frame(
  time = round(runif(n, 1, 100)),
  status = sample(0:1, n, replace = TRUE),
  trt = sample(0:1, n, replace = TRUE),
  age = rnorm(n, 50, 10),
  region = sample(c("A", "B"), n, replace = TRUE),
  subgroup = sample(c("S1", "S2", "S3"), n, replace = TRUE)
)

# Ensure variables are factors where appropriate
sim_data$trt <- factor(sim_data$trt, levels = c(0, 1))
sim_data$region <- as.factor(sim_data$region)
sim_data$subgroup <- as.factor(sim_data$subgroup)

# 2. Run prepare_formula_model
# This transforms the data (creating dummy variables for interactions)
# and builds the non-linear brms formula.
prepared_model <- prepare_formula_model(
  data = sim_data,
  
  # Main response variable and treatment identifier
  response_formula = Surv(time, status) ~ trt,
  
  # Predictive (Interaction) effects to be shrunk
  # Note: The function will automatically generate dummy columns for 'subgroup'
  shrunk_predictive_formula = ~ 0 + trt:subgroup,
  
  # Prognostic (Main) effects: Unshrunk (Fixed)
  unshrunk_terms_formula = ~ age,
  
  # Prognostic (Main) effects: Shrunk (Regularized)
  shrunk_prognostic_formula = ~ 0 + region,
  
  # Model type
  response_type = "survival",
  
  # Stratify the baseline hazard by region
  stratification_formula = ~ region
)

# 3. Inspect the Results

# A. The generated brms formula object
# You should see parts for 'unprogeffect', 'shprogeffect', etc.
print(prepared_model$formula)

# B. The processed data
# You should see new columns like 'subgroup_S1_x_trt', 'subgroup_S2_x_trt', etc.
head(prepared_model$data)
```

### Model Preparation 


### Example 2: Using Default Priors (Recommended)

The simplest approach: just provide `sigma_ref` and let the package use smart defaults that adapt to your outcome type.

```{r}
# For survival models, sigma_ref is typically 1
# For continuous outcomes, use sd(outcome)
sigma_ref <- 1  # Standard for survival models

fit_ex3 <- fit_brms_model(
  prepared_model = prepared_model,
  sigma_ref = sigma_ref,
  # All priors use defaults - no need to specify!
  chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = "cmdstanr"
)

# View the priors that were automatically set
cat("\n=== Priors Used ===\n")
print(prior_summary(fit_ex3))
```

### Example 3: Using the R2D2 Shrinkage Prior

The R2D2 prior is useful when you want to control the *global* shrinkage via the coefficient of determination ($R^2$) rather than a scale parameter. This is often more interpretable for stakeholders.

```{r}
# Use a custom R2D2 prior for the shrunk predictive effects (interactions)
# mean_R2 = 0.5 implies we expect the subgroups to explain 50% of the variance
# This is more interpretable than abstract scale parameters

fit_ex4 <- fit_brms_model(
  prepared_model = prepared_model,
  sigma_ref = 1,
  shrunk_predictive_prior = "R2D2(mean_R2 = 0.5, prec_R2 = 1)",
  # Can also customize other priors
  intercept_prior = "normal(0, 5 * sigma_ref)",
  unshrunk_prior = "normal(0, 2.5 * sigma_ref)",
  chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = "cmdstanr"
)
```

### Example 4: Custom Hierarchical Prior (Advanced)

This example demonstrates injecting raw Stan code using `stanvars`. This is necessary if you want to implement a hierarchical structure that `brms` does not support natively, such as estimating a shared variance parameter across coefficients.

```{r}
library(brms)

# 1. Define new hyperparameters in Stan
# Declare parameters that will be estimated
stanvars_full_hierarchical <- brms::stanvar(
  scode = "  real mu_pred;\n  real<lower=0> sigma_pred;\n",
  block = "parameters"
) +
  # Add priors for these parameters
  brms::stanvar(
    scode = "  // Priors on the hierarchical parameters\n  target += normal_lpdf(mu_pred | 0, 4); \n  target += normal_lpdf(sigma_pred | 0, 1) - normal_lccdf(0 | 0, 1); \n",
    block = "model"
  )

# 2. Create prior that references the Stan variables
prior_full_hierarchical <- brms::set_prior("normal(mu_pred, sigma_pred)")

# 3. Pass both to fit_brms_model
fit_ex5 <- fit_brms_model(
  prepared_model = prepared_model,
  sigma_ref = 1,
  shrunk_predictive_prior = prior_full_hierarchical,
  stanvars = stanvars_full_hierarchical,
  # Other priors can still use sigma_ref
  intercept_prior = "normal(0, 5 * sigma_ref)",
  unshrunk_prior = "normal(0, 2.5 * sigma_ref)",
  chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = "cmdstanr"
)

# View the estimated hyperparameters
cat("\n=== Estimated Hierarchical Parameters ===\n")
mu_pred_samples <- as.data.frame(fit_ex5)$mu_pred
sigma_pred_samples <- as.data.frame(fit_ex5)$sigma_pred

if (!is.null(mu_pred_samples)) {
  cat("mu_pred: ", round(mean(mu_pred_samples), 3), 
      " (SD: ", round(sd(mu_pred_samples), 3), ")\n")
}
if (!is.null(sigma_pred_samples)) {
  cat("sigma_pred: ", round(mean(sigma_pred_samples), 3), 
      " (SD: ", round(sd(sigma_pred_samples), 3), ")\n")
}
```

# Advanced Model Parameterization

This section demonstrates advanced features for controlling how your model represents subgroups and priors.

## Example 5: One-Hot Encoding for Interaction Terms

**NEW FEATURE:** When you use `~ 0 + trt:factor_var`, ALL levels of the factor will appear in the interaction (not k-1 levels). This gives you full control over the model parameterization.

```{r}
# Create sample data with multiple subgroups
set.seed(456)
n_patients <- 180
sample_data_onehot <- data.frame(
  id = 1:n_patients,
  trt = factor(sample(0:1, n_patients, replace = TRUE)),
  outcome = rnorm(n_patients, 50, 10),
  age = rnorm(n_patients, 65, 10),
  biomarker = factor(sample(c("Low", "Medium", "High"), n_patients, replace = TRUE))
)

# Compare: Standard vs One-Hot Encoding
cat("\\n=== Standard Encoding (k-1 levels) ===\\n")
cat("~ trt:biomarker gives k-1 = 2 interaction terms (reference category excluded)\\n\\n")

cat("=== One-Hot Encoding (ALL levels) ===\\n")
cat("~ 0 + trt:biomarker gives k = 3 interaction terms (all categories included)\\n\\n")

# Prepare with one-hot encoding
prepared_onehot <- prepare_formula_model(
  data = sample_data_onehot,
  response_formula = outcome ~ trt,
  unshrunk_terms_formula = ~ age,
  shrunk_predictive_formula = ~ 0 + trt:biomarker,  # Note the "0 +" prefix!
  response_type = "continuous"
)

# Fit the model
sigma_ref <- sd(sample_data_onehot$outcome)
fit_onehot <- fit_brms_model(
  prepared_model = prepared_onehot,
  sigma_ref = sigma_ref,
  chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = "cmdstanr"
)

# Check coefficients - you should see ALL three biomarker levels
cat("\\n=== All Biomarker Levels in Interaction ===\\n")
coefs_onehot <- fixef(fit_onehot)
print(coefs_onehot[grepl("biomarker", rownames(coefs_onehot)), ])

cat("\\n=== Advantage ===\\n")
cat("All biomarker levels treated symmetrically - no arbitrary reference category\\n")
```

## Example 6: Coefficient-Specific Priors

**ADVANCED FEATURE:** You can set different priors for specific coefficients by passing a `brmsprior` object (created with `c()`).

*Scenario*: Set a general prior for all unshrunk terms, but use a tighter prior specifically for treatment-biomarker interactions.

```{r}
# Prepare model with biomarker:trt interaction in unshrunk terms
prepared_specific <- prepare_formula_model(
  data = sample_data_onehot,
  response_formula = outcome ~ trt,
  unshrunk_terms_formula = ~ age + trt:biomarker,  # Interaction in unshrunk
  response_type = "continuous"
)

sigma_ref <- sd(sample_data_onehot$outcome)

cat("\\n=== Prior Strategy ===\\n")
cat("General unshrunk prior: normal(0,", round(5 * sigma_ref, 2), ")\\n")
cat("Specific for trt:biomarker: normal(0,", round(1 * sigma_ref, 2), ")\\n\\n")

# Create combined prior object
# IMPORTANT: Use EXACT coefficient names - check with get_prior() if unsure
unshrunk_priors_combined <- c(
  brms::set_prior("normal(0, 5 * sigma_ref)", class = "b"),  # General
  brms::set_prior("normal(0, 1 * sigma_ref)", class = "b", coef = "trt:biomarkerLow"),
  brms::set_prior("normal(0, 1 * sigma_ref)", class = "b", coef = "trt:biomarkerMedium")
)

# Fit the model
fit_specific <- fit_brms_model(
  prepared_model = prepared_specific,
  sigma_ref = sigma_ref,
  unshrunk_prior = unshrunk_priors_combined,  # Pass the combined object
  chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = "cmdstanr"
)

cat("\n=== Coefficient Estimates ===\n")
coefs_specific <- fixef(fit_specific)
cat("\nAge (general prior):\n")
print(coefs_specific["unshrunktermeffect_age", ])
cat("\nTreatment:biomarker (tighter prior):\n")
print(coefs_specific[grepl("trt.*:biomarker", rownames(coefs_specific)), ])
```

## Example 7: Hierarchical Priors with Shared Variance (stanvars)

**VERY ADVANCED FEATURE:** Create correlated priors by sharing a common variance parameter estimated from the data.

*Use case*: When you believe treatment effects across subgroups should be exchangeable, you can pool information by giving them a shared variance.

```{r}
# Prepare model
prepared_corr <- prepare_formula_model(
  data = sample_data_onehot,
  response_formula = outcome ~ trt,
  unshrunk_terms_formula = ~ age + trt:biomarker,
  response_type = "continuous"
)

sigma_ref <- sd(sample_data_onehot$outcome)

cat("\n=== Hierarchical Prior Structure ===\n")
cat("Instead of independent priors, we'll use a shared variance:\n")
cat("  tau ~ half-normal(0, 1)  [shared variance parameter]\n")
cat("  beta_Low ~ N(0, tau)\n")
cat("  beta_Medium ~ N(0, tau)\n")
cat("This creates exchangeability and adaptive shrinkage.\n\n")

# Step 1: Declare tau as a parameter to be estimated
tau_parameter <- brms::stanvar(
  scode = "  real<lower=0> biomarker_tau;  // Shared variance\n",
  block = "parameters"
)

# Step 2: Add prior for tau
tau_prior <- brms::stanvar(
  scode = "  biomarker_tau ~ normal(0, 1);  // Hyperprior\n",
  block = "model"
)

# Combine stanvars
hierarchical_stanvars <- tau_parameter + tau_prior

# Step 3: Create priors referencing the estimated tau
unshrunk_priors_hier <- c(
  brms::set_prior("normal(0, 5 * sigma_ref)", class = "b"),  # General
  brms::set_prior("normal(0, biomarker_tau)", class = "b", coef = "trt:biomarkerLow"),
  brms::set_prior("normal(0, biomarker_tau)", class = "b", coef = "trt:biomarkerMedium")
)

# Step 4: Fit the hierarchical model
fit_hier <- fit_brms_model(
  prepared_model = prepared_corr,
  sigma_ref = sigma_ref,
  unshrunk_prior = unshrunk_priors_hier,
  stanvars = hierarchical_stanvars,
  chains = 1, iter = 400, warmup = 200, cores = 1, refresh = 0, backend = "cmdstanr"
)

# Extract the estimated tau
cat("\n=== Estimated Shared Variance ===\n")
tau_samples <- as.data.frame(fit_hier)$biomarker_tau
if (!is.null(tau_samples) && length(tau_samples) > 0) {
  cat("Posterior mean:", round(mean(tau_samples), 3), "\n")
  cat("95% CI: [", round(quantile(tau_samples, 0.025), 3), ",", 
      round(quantile(tau_samples, 0.975), 3), "]\n\n")
  cat("Interpretation:\n")
  cat("- Small tau: Effects tightly clustered (strong shrinkage)\n")
  cat("- Large tau: Effects show substantial variability (weak shrinkage)\n")
  cat("- Data-driven: tau adapts automatically\n")
}
```

#Stratification for Nuisance Parameters 

In many trials, parameters like the observation error variance ($\sigma^2$ for continuous outcomes) or the baseline hazard function ($h_0(t)$ for survival outcomes) are known to vary by site, country, or other factors. Stratification models this known heterogeneity by fitting these nuisance parameters separately for each level of a grouping variable.

Use the `stratification_formula_str` argument to define the grouping factor(s).

## Example 8: Stratified Continuous Model

*Scenario*: We model SBP change where the observation **variance** $\sigma^2$ differs by $\text{clinic\_site}$. This is modeled by stratifying the $\sigma$ parameter in the Normal distribution by the site variable.

```{r}
set.seed(42)
n_patients <- 180
sigma_by_site <- c(SiteA = 6, SiteB = 12, SiteC = 18)
sample_data_strat_cont <- data.frame(
    id = 1:n_patients,
    clinic_site = factor(sample(c("SiteA", "SiteB", "SiteC"), n_patients, replace = TRUE))
)
sample_data_strat_cont$trt <- factor(sample(0:1, n_patients, replace = TRUE, prob = c(0.5, 0.5)))
sample_data_strat_cont$baseline_sbp <- rnorm(n_patients, mean = 145, sd = 8)
sample_data_strat_cont$age_group <- factor(sample(c("Under60", "Over60"), n_patients, replace = TRUE))
noise <- rnorm(n_patients, mean = 0, sd = sigma_by_site[sample_data_strat_cont$clinic_site])
sample_data_strat_cont$sbp_change <- -5 - (as.integer(sample_data_strat_cont$trt)-1) * 8 -
                                     0.2 * (sample_data_strat_cont$baseline_sbp - 145) +
                                     (as.integer(sample_data_strat_cont$trt)-1) * ifelse(sample_data_strat_cont$age_group == "Over60", -5, 0) +
                                     noise
```

```{r}
# Model Fitting with Stratified Sigma
# Calculate sigma_ref from the outcome SD
sigma_ref <- sd(sample_data_strat_cont$sbp_change)

fit_continuous_stratified <- run_brms_analysis(
  data = sample_data_strat_cont,
  response_formula = sbp_change ~ trt,
  response_type = "continuous",
  unshrunk_terms_formula = ~ baseline_sbp,
  shrunk_predictive_formula = ~ 0 + trt:age_group,
  stratification_formula = ~ clinic_site,
  sigma_ref = sigma_ref,
  chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = "cmdstanr"
)
```


```{r}
strat_continuous_summary <- summary_subgroup_effects(
  brms_fit = fit_continuous_stratified
  # All parameters automatically extracted!
)

print(strat_continuous_summary$estimates)
plot(strat_continuous_summary, title = "Stratified Continuous: Subgroup Effects")
```

## Example 9: Stratified Survival Model

*Scenario*: We model a time-to-event outcome where the **baseline hazard** $h_0(t)$ differs by $\text{country}$. This is particularly important for multi-regional trials where regional differences in standard of care affect baseline risk.

```{r}
set.seed(123)
n_patients <- 200
lambda_by_country <- c(US = 0.01, EU = 0.03)
surv_data_strat <- data.frame(
    id = 1:n_patients,
    country = factor(sample(c("US", "EU"), n_patients, replace = TRUE)),
    trt = factor(sample(0:1, n_patients, replace = TRUE)),
    age = rnorm(n_patients, 65, 10),
    biomarker = factor(sample(c("Low", "High"), n_patients, replace = TRUE))
)
lp <- (as.integer(surv_data_strat$trt)-1) * -0.6 + (surv_data_strat$age - 65) * 0.03 +
      (as.integer(surv_data_strat$trt)-1) * (as.integer(surv_data_strat$biomarker) - 1) * -0.5
u <- runif(n_patients)
lambda_vec <- lambda_by_country[surv_data_strat$country]
gamma <- 1.5 # Weibull shape parameter
true_event_time <- (-log(u) / (lambda_vec * exp(lp)))^(1/gamma)
censoring_time <- 60 # Administrative censoring time
surv_data_strat$event_status <- ifelse(true_event_time <= censoring_time, 1, 0)
surv_data_strat$event_time <- pmin(true_event_time, censoring_time)
```

```{r}
# Model Fitting with Stratified Baseline Hazard
fit_surv_stratified <- run_brms_analysis(
  data = surv_data_strat,
  response_formula = Surv(event_time, event_status) ~ trt,
  response_type = "survival",
  unshrunk_terms_formula = ~ age,
  shrunk_predictive_formula = ~ 0 + trt:biomarker,
  stratification_formula = ~ country,
  sigma_ref = 1,  # For survival models, typically use 1
  chains = 1, iter = 200, warmup = 100, cores = 1, refresh = 0, backend = "cmdstanr"
)
```

```{r ex6-summary-plot}
strat_surv_summary <- summary_subgroup_effects(
  brms_fit = fit_surv_stratified
  # All parameters automatically extracted!
)

print(strat_surv_summary$estimates)
plot(strat_surv_summary, title = "Stratified Survival: Subgroup Effects (AHR)")
```

# Summary

This vignette demonstrated advanced functionalities in `bonsaiforest2`:

1. **Offset variables** for count outcomes with varying exposure times
2. **Custom prior specification** with the new `sigma_ref` API
3. **One-hot encoding** for full factor representation in interactions
4. **Coefficient-specific priors** for fine-grained control
5. **Hierarchical priors** with shared variance using `stanvars`
6. **Stratification** for nuisance parameters that vary by groups

These features provide researchers with powerful tools for complex trial analyses while maintaining the principled Bayesian shrinkage framework.
